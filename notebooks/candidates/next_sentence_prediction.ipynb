{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Sentence Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mostendorff/miniconda2/envs/storytelling-candidates/bin/python\r\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformers==4.2.2\r\n"
     ]
    }
   ],
   "source": [
    "!pip freeze|grep transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/experiments/mostendorff/storytelling-candidates/environments\n",
      "Environment detected: gpu_server2 (in default.yml)\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from smart_open import open\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import json\n",
    "import pickle\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "from IPython.core.display import display\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "\n",
    "#sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from experiments.environment import get_env\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "os.environ['WANDB_DISABLED'] = 'true'\n",
    "\n",
    "env = get_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Feb 23 15:43:41 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 440.31       Driver Version: 440.31       CUDA Version: 10.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce RTX 208...  On   | 00000000:1B:00.0 Off |                  N/A |\r\n",
      "| 27%   32C    P8    11W / 250W |      0MiB / 11019MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  Quadro RTX 6000     On   | 00000000:1C:00.0 Off |                  Off |\r\n",
      "| 33%   26C    P8     4W / 260W |   1511MiB / 24220MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   2  Quadro RTX 6000     On   | 00000000:1D:00.0 Off |                  Off |\r\n",
      "| 33%   34C    P8    34W / 260W |      0MiB / 24220MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   3  Quadro RTX 6000     On   | 00000000:1E:00.0 Off |                  Off |\r\n",
      "| 33%   29C    P8    14W / 260W |      0MiB / 24220MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   4  GeForce RTX 208...  On   | 00000000:3D:00.0 Off |                  N/A |\r\n",
      "| 27%   26C    P8    20W / 250W |      0MiB / 11019MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   5  Quadro RTX 6000     On   | 00000000:3F:00.0 Off |                  Off |\r\n",
      "| 33%   26C    P8    17W / 260W |      0MiB / 24220MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   6  Quadro RTX 6000     On   | 00000000:40:00.0 Off |                  Off |\r\n",
      "| 33%   30C    P8    29W / 260W |      0MiB / 24220MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   7  Quadro RTX 6000     On   | 00000000:41:00.0 Off |                  Off |\r\n",
      "| 33%   27C    P8    17W / 260W |      0MiB / 24220MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    1     81557      C   /usr/bin/python                             1499MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1,2,3,5,6,7'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2,3,5,6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "from typing import Dict\n",
    "from transformers.data import metrics\n",
    "from transformers import EvalPrediction\n",
    "\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support, f1_score\n",
    "from scipy.special import softmax\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import BertForNextSentencePrediction, BertTokenizerFast, BertForSequenceClassification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./output/nsp/bert-base-cased'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir = './output/nsp'\n",
    "\n",
    "data_dir = '/data/experiments/hensel/storytelling-candidates/data'\n",
    "\n",
    "train_batch_size = 24\n",
    "eval_batch_size = 28\n",
    "\n",
    "model_name = 'bert-base-cased'\n",
    "#model_name = 's2orc-scibert'\n",
    "\n",
    "model_name_or_path = os.path.join(env['bert_dir'], model_name)\n",
    "\n",
    "model_output_dir = os.path.join(output_dir, model_name)\n",
    "model_output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>736-0</th>\n",
       "      <td>736</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>Hu Jintao, the President of the People's Repub...</td>\n",
       "      <td>https://en.wikinews.org/wiki?curid=736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736-1</th>\n",
       "      <td>736</td>\n",
       "      <td>38</td>\n",
       "      <td>49</td>\n",
       "      <td>Lunch was a traditional Brazilian barbecue wit...</td>\n",
       "      <td>https://en.wikinews.org/wiki?curid=736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741-1</th>\n",
       "      <td>741</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>Acting president Rawhi Fattuh has announced to...</td>\n",
       "      <td>https://en.wikinews.org/wiki?curid=741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741-2</th>\n",
       "      <td>741</td>\n",
       "      <td>17</td>\n",
       "      <td>53</td>\n",
       "      <td>Futtuh, head of the Palestinian parliament, wa...</td>\n",
       "      <td>https://en.wikinews.org/wiki?curid=741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741-3</th>\n",
       "      <td>741</td>\n",
       "      <td>54</td>\n",
       "      <td>84</td>\n",
       "      <td>New leadership could prove to be the key to re...</td>\n",
       "      <td>https://en.wikinews.org/wiki?curid=741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2909884-44</th>\n",
       "      <td>2909884</td>\n",
       "      <td>1032</td>\n",
       "      <td>1042</td>\n",
       "      <td>Consequently there are water, road and infrast...</td>\n",
       "      <td>https://en.wikinews.org/wiki?curid=2909884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2909884-45</th>\n",
       "      <td>2909884</td>\n",
       "      <td>1043</td>\n",
       "      <td>1065</td>\n",
       "      <td>We aim to make Groom a marginal electorate, if...</td>\n",
       "      <td>https://en.wikinews.org/wiki?curid=2909884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2909884-46</th>\n",
       "      <td>2909884</td>\n",
       "      <td>1066</td>\n",
       "      <td>1091</td>\n",
       "      <td>My approach is to listen to the community and ...</td>\n",
       "      <td>https://en.wikinews.org/wiki?curid=2909884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2909884-47</th>\n",
       "      <td>2909884</td>\n",
       "      <td>1092</td>\n",
       "      <td>1109</td>\n",
       "      <td>The principles of Liberal Democrats are the pr...</td>\n",
       "      <td>https://en.wikinews.org/wiki?curid=2909884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2910010-0</th>\n",
       "      <td>2910010</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>Delete this line, and start typing your articl...</td>\n",
       "      <td>https://en.wikinews.org/wiki?curid=2910010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175720 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             doc_id  start   end  \\\n",
       "sent_id                            \n",
       "736-0           736      0    37   \n",
       "736-1           736     38    49   \n",
       "741-1           741      0    16   \n",
       "741-2           741     17    53   \n",
       "741-3           741     54    84   \n",
       "...             ...    ...   ...   \n",
       "2909884-44  2909884   1032  1042   \n",
       "2909884-45  2909884   1043  1065   \n",
       "2909884-46  2909884   1066  1091   \n",
       "2909884-47  2909884   1092  1109   \n",
       "2910010-0   2910010      0    11   \n",
       "\n",
       "                                                         text  \\\n",
       "sent_id                                                         \n",
       "736-0       Hu Jintao, the President of the People's Repub...   \n",
       "736-1       Lunch was a traditional Brazilian barbecue wit...   \n",
       "741-1       Acting president Rawhi Fattuh has announced to...   \n",
       "741-2       Futtuh, head of the Palestinian parliament, wa...   \n",
       "741-3       New leadership could prove to be the key to re...   \n",
       "...                                                       ...   \n",
       "2909884-44  Consequently there are water, road and infrast...   \n",
       "2909884-45  We aim to make Groom a marginal electorate, if...   \n",
       "2909884-46  My approach is to listen to the community and ...   \n",
       "2909884-47  The principles of Liberal Democrats are the pr...   \n",
       "2910010-0   Delete this line, and start typing your articl...   \n",
       "\n",
       "                                                   url  \n",
       "sent_id                                                 \n",
       "736-0           https://en.wikinews.org/wiki?curid=736  \n",
       "736-1           https://en.wikinews.org/wiki?curid=736  \n",
       "741-1           https://en.wikinews.org/wiki?curid=741  \n",
       "741-2           https://en.wikinews.org/wiki?curid=741  \n",
       "741-3           https://en.wikinews.org/wiki?curid=741  \n",
       "...                                                ...  \n",
       "2909884-44  https://en.wikinews.org/wiki?curid=2909884  \n",
       "2909884-45  https://en.wikinews.org/wiki?curid=2909884  \n",
       "2909884-46  https://en.wikinews.org/wiki?curid=2909884  \n",
       "2909884-47  https://en.wikinews.org/wiki?curid=2909884  \n",
       "2910010-0   https://en.wikinews.org/wiki?curid=2910010  \n",
       "\n",
       "[175720 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df = pd.read_csv(os.path.join(data_dir, 'meta_data-12-02-21.tsv'), sep='\\t', index_col=0)\n",
    "meta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 11:46:18 - INFO - __main__ -   Train: 13089, Test: 3273\n"
     ]
    }
   ],
   "source": [
    "train_doc_ids, test_doc_ids = train_test_split(meta_df.doc_id.unique().tolist(), test_size=0.2, random_state=1)\n",
    "\n",
    "logger.info(f'Train: {len(train_doc_ids)}, Test: {len(test_doc_ids)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub sample\n",
    "#doc_ids = random.sample(meta_df.doc_id.unique().tolist(), 1000)\n",
    "#len(doc_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /home/mostendorff/datasets/BERT_pre_trained_models/pytorch/bert-base-cased were not used when initializing BertForNextSentencePrediction: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForNextSentencePrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForNextSentencePrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "model = BertForNextSentencePrediction.from_pretrained(model_name_or_path)\n",
    "#model = BertForSequenceClassification.from_pretrained(model_name_or_path, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NSPDataset(Dataset):\n",
    "    \"\"\"   \n",
    "    0 indicates sequence B is a continuation of sequence A,\n",
    "\n",
    "    1 indicates sequence B is a random sequence.\n",
    "    \"\"\"\n",
    "    max_length = 256\n",
    "    neg_ratio = 1.0\n",
    "    positive_label = 0\n",
    "    negative_label = 1\n",
    "    \n",
    "    def __init__(self, df, doc_ids, hf_tokenizer, return_labels=True, sample_n=0):\n",
    "        self.df = df\n",
    "        self.doc_ids = doc_ids\n",
    "        self.tokenizer = hf_tokenizer\n",
    "        self.return_labels = return_labels\n",
    "        self.sample_n = sample_n\n",
    "        self.inputs = []\n",
    "        self.samples = []\n",
    "\n",
    "    def load(self):\n",
    "        logger.info(f'Dataframe size: {len(self.df)}')\n",
    "        \n",
    "        # sub-sample\n",
    "        if self.sample_n > 0:\n",
    "            logger.info('Sub-sampling..')\n",
    "            self.doc_ids = random.sample(self.doc_ids, self.sample_n)\n",
    "        \n",
    "        # filter by doc ids\n",
    "        self.df = self.df[self.df.doc_id.isin(self.doc_ids)]\n",
    "\n",
    "        # positives\n",
    "        positive_pairs = set()\n",
    "\n",
    "        for doc_id, doc_df in self.df.groupby('doc_id'):\n",
    "            # positive samples\n",
    "            prev_sentence = None\n",
    "\n",
    "            for sent in doc_df.sort_values('start')['text']:\n",
    "                if len(sent) > 50:\n",
    "                    if prev_sentence is not None:\n",
    "                        pair = (prev_sentence, sent)\n",
    "\n",
    "                        positive_pairs.add(pair)\n",
    "\n",
    "                    prev_sentence = sent\n",
    "            \n",
    "        logger.info(f'Postive samples: {len(positive_pairs)}')\n",
    "        \n",
    "        # negatives\n",
    "        negative_pairs = set()        \n",
    "        neg_needed = int(self.neg_ratio * len(positive_pairs))\n",
    "        tries = 0\n",
    "\n",
    "        logger.info(f'Randomly selecting {neg_needed} negative samples (ratio={self.neg_ratio})')\n",
    "        \n",
    "        sents = meta_df[['doc_id', 'text']].values.tolist()\n",
    "        random.shuffle(sents)\n",
    "        \n",
    "        rand_sents = sents\n",
    "        rand_pairs = iter([rand_sents[i:i+2] for i in range(0, len(rand_sents), 2)])\n",
    "\n",
    "        while len(negative_pairs) < neg_needed:\n",
    "            (a_doc_id, a_sent), (b_doc_id, b_sent) = next(rand_pairs)\n",
    "            \n",
    "            #print(a_doc_id)\n",
    "\n",
    "            pair = (a_sent, b_sent)\n",
    "            \n",
    "            # TODO # and pair not in positive_pairs and pair not in negative_pairs\n",
    "            if a_doc_id != b_doc_id:\n",
    "                negative_pairs.add(pair)\n",
    "            else:\n",
    "                tries += 1\n",
    "\n",
    "        logger.info(f'done after {tries} invalid tries')\n",
    "\n",
    "        logger.info(f'Tokenize... {len(positive_pairs):,} + {len(negative_pairs):,} samples')\n",
    "\n",
    "        self.inputs = self.tokenizer(\n",
    "            text=[a for a, b in positive_pairs] + [a for a, b in negative_pairs],\n",
    "            text_pair=[b for a, b in positive_pairs] + [b for a, b in negative_pairs],\n",
    "            add_special_tokens=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            truncation=True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        \n",
    "        if self.return_labels:\n",
    "            labels = [self.positive_label] * len(positive_pairs)\n",
    "            labels += [self.negative_label] * len(negative_pairs)\n",
    "            self.inputs['labels'] = torch.tensor(labels)\n",
    "\n",
    "        logger.info('Dataset loaded')\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {k: v[idx] for k, v in self.inputs.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 11:47:23 - INFO - __main__ -   Dataframe size: 175720\n",
      "2021-02-19 11:47:23 - INFO - __main__ -   Sub-sampling..\n",
      "2021-02-19 11:47:24 - INFO - __main__ -   Postive samples: 48189\n",
      "2021-02-19 11:47:24 - INFO - __main__ -   Randomly selecting 48189 negative samples (ratio=1.0)\n",
      "2021-02-19 11:47:25 - INFO - __main__ -   done after 4 invalid tries\n",
      "2021-02-19 11:47:25 - INFO - __main__ -   Tokenize... 48,189 + 48,189 samples\n",
      "2021-02-19 11:47:33 - INFO - __main__ -   Dataset loaded\n"
     ]
    }
   ],
   "source": [
    "train_ds = NSPDataset(meta_df, train_doc_ids, tokenizer, return_labels=True, sample_n=5000)\n",
    "train_ds.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 11:47:33 - INFO - __main__ -   Dataframe size: 175720\n",
      "2021-02-19 11:47:33 - INFO - __main__ -   Sub-sampling..\n",
      "2021-02-19 11:47:33 - INFO - __main__ -   Postive samples: 4823\n",
      "2021-02-19 11:47:33 - INFO - __main__ -   Randomly selecting 4823 negative samples (ratio=1.0)\n",
      "2021-02-19 11:47:34 - INFO - __main__ -   done after 1 invalid tries\n",
      "2021-02-19 11:47:34 - INFO - __main__ -   Tokenize... 4,823 + 4,823 samples\n",
      "2021-02-19 11:47:35 - INFO - __main__ -   Dataset loaded\n"
     ]
    }
   ],
   "source": [
    "test_ds = NSPDataset(meta_df, test_doc_ids, tokenizer, return_labels=True, sample_n=500)\n",
    "test_ds.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_metrics(predict_out: EvalPrediction) -> Dict:\n",
    "    y_true = predict_out.label_ids\n",
    "    y_pred = np.argmax(predict_out.predictions, axis=1)\n",
    "\n",
    "    return {\n",
    "        \"f1_micro\": f1_score(y_true, y_pred, average='micro'),\n",
    "        \"f1_macro\": f1_score(y_true, y_pred, average='macro'),  \n",
    "        \"classification_report\": classification_report(\n",
    "            y_true, y_pred, \n",
    "            labels=[0,1], \n",
    "            target_names=['pos','neg'],\n",
    "            output_dict=True,\n",
    "        ),\n",
    "        \"classification_report_str\": classification_report(\n",
    "            y_true, y_pred, \n",
    "            labels=[0,1], \n",
    "            target_names=['pos','neg'],\n",
    "        )\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=model_output_dir,\n",
    "        overwrite_output_dir=True,\n",
    "        learning_rate=2e-5,\n",
    "        do_train=True,\n",
    "        num_train_epochs=3,\n",
    "        per_device_train_batch_size=train_batch_size,  \n",
    "        per_device_eval_batch_size=eval_batch_size,          \n",
    "        save_steps=0,\n",
    "        save_total_limit=3,\n",
    "        eval_steps=50,\n",
    "        do_eval=True,\n",
    "    ),\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=test_ds,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mostendorff/miniconda2/envs/storytelling-candidates/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='3012' max='3012' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3012/3012 28:51, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.212200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.186900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.099700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.101500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.048400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.048700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3012, training_loss=0.11593963657994352, metrics={'train_runtime': 1740.6394, 'train_samples_per_second': 1.73, 'total_flos': 48102338876221440, 'epoch': 3.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_out = trainer.train()\n",
    "train_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./output/nsp/bert-base-cased/tokenizer_config.json',\n",
       " './output/nsp/bert-base-cased/special_tokens_map.json',\n",
       " './output/nsp/bert-base-cased/vocab.txt',\n",
       " './output/nsp/bert-base-cased/added_tokens.json')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model()\n",
    "tokenizer.save_pretrained(model_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='87' max='87' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [87/87 00:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict_out = trainer.predict(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pos       0.94      0.91      0.93      4823\n",
      "         neg       0.91      0.94      0.93      4823\n",
      "\n",
      "    accuracy                           0.93      9646\n",
      "   macro avg       0.93      0.93      0.93      9646\n",
      "weighted avg       0.93      0.93      0.93      9646\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(compute_metrics(predict_out)['classification_report_str'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict for sentences with high similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create your own dataset\n",
    "class PredictNSPDataset(Dataset):\n",
    "    max_length = 256\n",
    "    \n",
    "    def __init__(self, sent_id2text, sim_df, hf_tokenizer, min_sim=0., max_sim=1., sample_n=0):\n",
    "        self.sent_id2text = sent_id2text\n",
    "        self.sim_df = sim_df\n",
    "        self.tokenizer = hf_tokenizer\n",
    "        self.min_sim = min_sim\n",
    "        self.max_sim = max_sim\n",
    "        self.sample_n = sample_n\n",
    "        self.inputs = []\n",
    "        self.samples = []\n",
    "\n",
    "    def load(self):\n",
    "\n",
    "        self.sent1_ids = []\n",
    "        self.sent2_ids = []\n",
    "\n",
    "        texts1 = []\n",
    "        texts2 = []\n",
    "\n",
    "\n",
    "        logger.info(f'sent_id2text size: {len(self.sent_id2text)}')\n",
    "        \n",
    "        if self.sim_df is None:\n",
    "            # Random pairs\n",
    "            sent_ids = list(self.sent_id2text.keys())\n",
    "            sent_id_pairs = combinations(sent_ids, 2)\n",
    "            \n",
    "            logger.info(f'Possible pairs: {(len(sent_ids) *(len(sent_ids)-1))/2:,}')\n",
    "            \n",
    "            \n",
    "            #    logger.info('Sub-sampling..')\n",
    "            #    sent_id_pairs = random.sample(list(sent_id_pairs), self.sample_n)\n",
    "            \n",
    "\n",
    "            for a, b in sent_id_pairs:\n",
    "                if self.sample_n > 0 and len(texts1) > self.sample_n:\n",
    "                    logger.info('stop...')\n",
    "                    break\n",
    "                    \n",
    "                self.sent1_ids.append(a)\n",
    "                self.sent2_ids.append(b)\n",
    "\n",
    "                texts1.append(self.sent_id2text[a])\n",
    "                texts2.append(self.sent_id2text[b])\n",
    "\n",
    "        \n",
    "        else:\n",
    "            # Using similarity as candidate filter\n",
    "            \n",
    "            logger.info(f'Similarity dataframe size: {len(self.sim_df)}')\n",
    "\n",
    "            # filter        \n",
    "            self.sim_df = self.sim_df[(self.sim_df.similarity >= self.min_sim) & (self.sim_df.similarity <= self.max_sim)]\n",
    "\n",
    "            # sub-sample\n",
    "            if self.sample_n > 0:\n",
    "                logger.info('Sub-sampling..')\n",
    "                self.sim_df = self.sim_df.sample(self.sample_n)\n",
    "\n",
    "            for a, b in self.sim_df[['sent1_id', 'sent2_id']].values:\n",
    "                if a in self.sent_id2text and b in self.sent_id2text:\n",
    "                    self.sent1_ids.append(a)\n",
    "                    self.sent2_ids.append(b)\n",
    "\n",
    "                    texts1.append(self.sent_id2text[a])\n",
    "                    texts2.append(self.sent_id2text[b])\n",
    "                     \n",
    "        logger.info(f'Tokenize... {len(texts1):,} samples')\n",
    "\n",
    "        self.inputs = self.tokenizer(\n",
    "            text=texts1,\n",
    "            text_pair=texts2,\n",
    "            add_special_tokens=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            truncation=True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        \n",
    "        logger.info('Dataset loaded')\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {k: v[idx] for k, v in self.inputs.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load similarity dataframe\n",
    "sim_df = pd.read_csv(os.path.join(data_dir, 'sentence_pairs-12-02-21.tsv'), sep='\\t')\n",
    "sent_id2text = {sent_id: row['text'] for sent_id, row in meta_df.iterrows()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent1_id</th>\n",
       "      <th>sent2_id</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>146327-5</td>\n",
       "      <td>128379-7</td>\n",
       "      <td>0.941311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>411276-6</td>\n",
       "      <td>68858-3</td>\n",
       "      <td>0.944875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100821-2</td>\n",
       "      <td>100783-28</td>\n",
       "      <td>0.941018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>170782-2</td>\n",
       "      <td>83662-160</td>\n",
       "      <td>0.946984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>71884-34</td>\n",
       "      <td>6530-0</td>\n",
       "      <td>0.940196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>83313-15</td>\n",
       "      <td>127214-3</td>\n",
       "      <td>0.940489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>80368-2</td>\n",
       "      <td>139252-2</td>\n",
       "      <td>0.951340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>117466-20</td>\n",
       "      <td>189339-7</td>\n",
       "      <td>0.941416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>53040-2</td>\n",
       "      <td>103883-4</td>\n",
       "      <td>0.940946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>88334-3</td>\n",
       "      <td>267748-75</td>\n",
       "      <td>0.941107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sent1_id   sent2_id  similarity\n",
       "0    146327-5   128379-7    0.941311\n",
       "1    411276-6    68858-3    0.944875\n",
       "2    100821-2  100783-28    0.941018\n",
       "3    170782-2  83662-160    0.946984\n",
       "4    71884-34     6530-0    0.940196\n",
       "..        ...        ...         ...\n",
       "95   83313-15   127214-3    0.940489\n",
       "96    80368-2   139252-2    0.951340\n",
       "97  117466-20   189339-7    0.941416\n",
       "98    53040-2   103883-4    0.940946\n",
       "99    88334-3  267748-75    0.941107\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-23 15:46:25 - INFO - __main__ -   sent_id2text size: 175720\n",
      "2021-02-23 15:46:25 - INFO - __main__ -   Similarity dataframe size: 100\n",
      "2021-02-23 15:46:25 - INFO - __main__ -   Tokenize... 100 samples\n",
      "2021-02-23 15:46:25 - INFO - __main__ -   Dataset loaded\n"
     ]
    }
   ],
   "source": [
    "# Tokenize dataset\n",
    "#pred_ds = PredictNSPDataset(sent_id2text, sim_df, tokenizer, min_sim=0, max_sim=1, sample_n=0)\n",
    "#pred_ds.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-23 15:46:26 - INFO - __main__ -   sent_id2text size: 175720\n",
      "2021-02-23 15:46:26 - INFO - __main__ -   Possible pairs: 15,438,671,340.0\n",
      "2021-02-23 15:46:27 - INFO - __main__ -   stop...\n",
      "2021-02-23 15:46:27 - INFO - __main__ -   Tokenize... 1,000,001 samples\n",
      "2021-02-23 15:48:17 - INFO - __main__ -   Dataset loaded\n"
     ]
    }
   ],
   "source": [
    "# Tokenize dataset / without similarity\n",
    "pred_ds = PredictNSPDataset(sent_id2text, None, tokenizer, sample_n=1_000_000)\n",
    "pred_ds.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load previously trained model from disk\n",
    "model = BertForNextSentencePrediction.from_pretrained('./output/nsp/bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_trainer = Trainer(\n",
    "    model=model,\n",
    "    args=TrainingArguments(\n",
    "        output_dir='./output/nsp__predict/bert-base-cased',\n",
    "        per_device_eval_batch_size=512,          \n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='1954' max='1954' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1954/1954 23:40]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_out = pred_trainer.predict(pred_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent1_id</th>\n",
       "      <th>sent2_id</th>\n",
       "      <th>is_next_sentence</th>\n",
       "      <th>is_not_next_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>736-0</td>\n",
       "      <td>736-1</td>\n",
       "      <td>2.445305e-04</td>\n",
       "      <td>1.028482e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>736-0</td>\n",
       "      <td>741-1</td>\n",
       "      <td>1.119650e-08</td>\n",
       "      <td>1.559122e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>736-0</td>\n",
       "      <td>741-2</td>\n",
       "      <td>1.085477e-08</td>\n",
       "      <td>1.662852e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>736-0</td>\n",
       "      <td>741-3</td>\n",
       "      <td>1.084755e-08</td>\n",
       "      <td>1.551225e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>736-0</td>\n",
       "      <td>741-4</td>\n",
       "      <td>1.123367e-08</td>\n",
       "      <td>1.534388e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>741-4</td>\n",
       "      <td>120767-1</td>\n",
       "      <td>9.893848e-09</td>\n",
       "      <td>1.974904e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>741-4</td>\n",
       "      <td>120767-2</td>\n",
       "      <td>1.027576e-08</td>\n",
       "      <td>1.819374e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>741-4</td>\n",
       "      <td>120767-3</td>\n",
       "      <td>1.013443e-08</td>\n",
       "      <td>1.883872e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>741-4</td>\n",
       "      <td>120767-6</td>\n",
       "      <td>9.978086e-09</td>\n",
       "      <td>1.969033e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000000</th>\n",
       "      <td>741-4</td>\n",
       "      <td>120767-7</td>\n",
       "      <td>1.006834e-08</td>\n",
       "      <td>1.999701e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000001 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sent1_id  sent2_id  is_next_sentence  is_not_next_sentence\n",
       "0          736-0     736-1      2.445305e-04          1.028482e-11\n",
       "1          736-0     741-1      1.119650e-08          1.559122e-06\n",
       "2          736-0     741-2      1.085477e-08          1.662852e-06\n",
       "3          736-0     741-3      1.084755e-08          1.551225e-06\n",
       "4          736-0     741-4      1.123367e-08          1.534388e-06\n",
       "...          ...       ...               ...                   ...\n",
       "999996     741-4  120767-1      9.893848e-09          1.974904e-06\n",
       "999997     741-4  120767-2      1.027576e-08          1.819374e-06\n",
       "999998     741-4  120767-3      1.013443e-08          1.883872e-06\n",
       "999999     741-4  120767-6      9.978086e-09          1.969033e-06\n",
       "1000000    741-4  120767-7      1.006834e-08          1.999701e-06\n",
       "\n",
       "[1000001 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "nsp_df = pd.DataFrame(dict(\n",
    "    sent1_id=pred_ds.sent1_ids, \n",
    "    sent2_id=pred_ds.sent2_ids, \n",
    "    is_next_sentence=softmax(pred_out.predictions[:,0]),\n",
    "    is_not_next_sentence=softmax(pred_out.predictions[:,1]),\n",
    "))\n",
    "\n",
    "\n",
    "nsp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent1_id</th>\n",
       "      <th>sent2_id</th>\n",
       "      <th>is_next_sentence</th>\n",
       "      <th>is_not_next_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>736-0</td>\n",
       "      <td>736-1</td>\n",
       "      <td>2.445305e-04</td>\n",
       "      <td>1.028482e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>736-0</td>\n",
       "      <td>743-0</td>\n",
       "      <td>6.225773e-05</td>\n",
       "      <td>1.341325e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>736-0</td>\n",
       "      <td>743-1</td>\n",
       "      <td>1.131110e-05</td>\n",
       "      <td>1.016266e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>736-0</td>\n",
       "      <td>797-0</td>\n",
       "      <td>3.154243e-07</td>\n",
       "      <td>7.666976e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>736-0</td>\n",
       "      <td>797-1</td>\n",
       "      <td>3.645239e-05</td>\n",
       "      <td>2.437960e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999945</th>\n",
       "      <td>741-4</td>\n",
       "      <td>120740-5</td>\n",
       "      <td>9.305423e-06</td>\n",
       "      <td>1.425404e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999946</th>\n",
       "      <td>741-4</td>\n",
       "      <td>120740-6</td>\n",
       "      <td>2.139979e-07</td>\n",
       "      <td>9.955527e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999948</th>\n",
       "      <td>741-4</td>\n",
       "      <td>120740-8</td>\n",
       "      <td>4.410176e-07</td>\n",
       "      <td>4.101011e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999950</th>\n",
       "      <td>741-4</td>\n",
       "      <td>120740-10</td>\n",
       "      <td>1.980110e-07</td>\n",
       "      <td>1.126044e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999971</th>\n",
       "      <td>741-4</td>\n",
       "      <td>120749-8</td>\n",
       "      <td>6.100128e-07</td>\n",
       "      <td>2.554929e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>158057 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sent1_id   sent2_id  is_next_sentence  is_not_next_sentence\n",
       "0         736-0      736-1      2.445305e-04          1.028482e-11\n",
       "8         736-0      743-0      6.225773e-05          1.341325e-10\n",
       "9         736-0      743-1      1.131110e-05          1.016266e-09\n",
       "12        736-0      797-0      3.154243e-07          7.666976e-08\n",
       "13        736-0      797-1      3.645239e-05          2.437960e-10\n",
       "...         ...        ...               ...                   ...\n",
       "999945    741-4   120740-5      9.305423e-06          1.425404e-09\n",
       "999946    741-4   120740-6      2.139979e-07          9.955527e-08\n",
       "999948    741-4   120740-8      4.410176e-07          4.101011e-08\n",
       "999950    741-4  120740-10      1.980110e-07          1.126044e-07\n",
       "999971    741-4   120749-8      6.100128e-07          2.554929e-08\n",
       "\n",
       "[158057 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_score = 0.1\n",
    "\n",
    "nsp_df[nsp_df.is_next_sentence > nsp_df.is_not_next_sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsp_df.to_csv('./output/nsp.1m.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:storytelling-candidates]",
   "language": "python",
   "name": "conda-env-storytelling-candidates-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
