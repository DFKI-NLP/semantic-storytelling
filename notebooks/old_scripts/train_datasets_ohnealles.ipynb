{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aquatic-australia",
   "metadata": {},
   "source": [
    "# Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8c9780a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model_checkpoint = 'bert-base-cased'\n",
    "batch_size = 2\n",
    "metric_name = \"accuracy\"\n",
    "num_epoch = 5\n",
    "\n",
    "# Fold\n",
    "num_folds = 4\n",
    "\n",
    "# Experiment\n",
    "labels = [\"none\", \"attribution\", \"causal\", \"conditional\", \"contrast\", \"description\", \"equivalence\", \"fulfillment\", \"identity\", \"purpose\", \"summary\", \"temporal\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfcfcb1",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d51af5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8188a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_fold(path, fold):\n",
    "    train = pd.read_csv(f\"{path}/train.{fold}.csv\")\n",
    "    test = pd.read_csv(f\"{path}/test.{fold}.csv\")\n",
    "    train_origin = train[\"origin\"].tolist()\n",
    "    train_target = train[\"target\"].tolist()\n",
    "    train_labels = train[\"label\"].tolist()\n",
    "    test_origin = test[\"origin\"].tolist()\n",
    "    test_target = test[\"target\"].tolist()\n",
    "    test_labels = test[\"label\"].tolist()\n",
    "    return train_origin, train_target, train_labels, test_origin, test_target, test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1845b3",
   "metadata": {},
   "source": [
    "# Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a464f6",
   "metadata": {},
   "source": [
    "## Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "verbal-lexington",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import collections\n",
    "\n",
    "#classification_threshold = 0.\n",
    "\n",
    "def flatten(d, parent_key='', sep='__'):\n",
    "    items = []\n",
    "    for k, v in d.items():\n",
    "        new_key = parent_key + sep + k if parent_key else k\n",
    "        if isinstance(v, collections.MutableMapping):\n",
    "            items.extend(flatten(v, new_key, sep=sep).items())\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    global labels\n",
    "    predictions, true_labels = eval_pred\n",
    "    # take most probable guess\n",
    "    predictions = np.argmax(predictions, axis=-1)\n",
    "    return flatten(classification_report(\n",
    "        y_true=true_labels,\n",
    "        y_pred=predictions,\n",
    "        target_names=labels,\n",
    "        zero_division=0,\n",
    "        output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "opened-gambling",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST\n",
    "#flatten(classification_report(\n",
    "#    y_true=[0,1,2,3,4,5,6,7,8,9,10,11,12],\n",
    "#    y_pred=[0,0,0,1,3,0,0,0,0,0,0,0,0],\n",
    "#    target_names=labels,\n",
    "#    zero_division=0,\n",
    "#    output_dict=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attractive-taste",
   "metadata": {},
   "source": [
    "## Model Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "referenced-wichita",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "args = TrainingArguments(\n",
    "    \"semantic-test\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_epoch,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=metric_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accomplished-wedding",
   "metadata": {},
   "source": [
    "## Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sensitive-growth",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast, DebertaTokenizerFast\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_checkpoint)\n",
    "#tokenizer = DebertaTokenizerFast.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b7ee1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5cf32517",
   "metadata": {},
   "source": [
    "## Print Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efbd918e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#train_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbe4fd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_random_elements(origin_list, target_list, label_list, encodings, num_examples=10):\n",
    "    global labels\n",
    "    assert num_examples <= len(origin_list), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(origin_list)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(origin_list)-1)\n",
    "        picks.append(pick)\n",
    "    data = []\n",
    "    for n in picks:\n",
    "        data.append([n, origin_list[n], labels[label_list[n]], target_list[n], encodings.input_ids[n], encodings.token_type_ids[n], encodings.attention_mask[n]])\n",
    "    df = pd.DataFrame(data, columns=['index', 'Origin', 'Label', 'Target', 'Input_ids', 'Token_type_ids', 'Attention_mask'])\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cb93df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_random_elements(train_origin, train_target, train_labels, train_encodings)\n",
    "# Output adjustet to Folds\n",
    "#show_random_elements(k_fold_origin[0][0], k_fold_target[0][0], k_fold_labels[0][0], train_encodings[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prospective-lightweight",
   "metadata": {},
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "impressive-worth",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemanticDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fresh-destiny",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ultimate-winning",
   "metadata": {},
   "source": [
    "## Train & Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "environmental-medication",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9380' max='9380' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9380/9380 12:31, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>None  Precision</th>\n",
       "      <th>None  Recall</th>\n",
       "      <th>None  F1-score</th>\n",
       "      <th>None  Support</th>\n",
       "      <th>Attribution  Precision</th>\n",
       "      <th>Attribution  Recall</th>\n",
       "      <th>Attribution  F1-score</th>\n",
       "      <th>Attribution  Support</th>\n",
       "      <th>Causal  Precision</th>\n",
       "      <th>Causal  Recall</th>\n",
       "      <th>Causal  F1-score</th>\n",
       "      <th>Causal  Support</th>\n",
       "      <th>Conditional  Precision</th>\n",
       "      <th>Conditional  Recall</th>\n",
       "      <th>Conditional  F1-score</th>\n",
       "      <th>Conditional  Support</th>\n",
       "      <th>Contrast  Precision</th>\n",
       "      <th>Contrast  Recall</th>\n",
       "      <th>Contrast  F1-score</th>\n",
       "      <th>Contrast  Support</th>\n",
       "      <th>Description  Precision</th>\n",
       "      <th>Description  Recall</th>\n",
       "      <th>Description  F1-score</th>\n",
       "      <th>Description  Support</th>\n",
       "      <th>Equivalence  Precision</th>\n",
       "      <th>Equivalence  Recall</th>\n",
       "      <th>Equivalence  F1-score</th>\n",
       "      <th>Equivalence  Support</th>\n",
       "      <th>Fulfillment  Precision</th>\n",
       "      <th>Fulfillment  Recall</th>\n",
       "      <th>Fulfillment  F1-score</th>\n",
       "      <th>Fulfillment  Support</th>\n",
       "      <th>Identity  Precision</th>\n",
       "      <th>Identity  Recall</th>\n",
       "      <th>Identity  F1-score</th>\n",
       "      <th>Identity  Support</th>\n",
       "      <th>Purpose  Precision</th>\n",
       "      <th>Purpose  Recall</th>\n",
       "      <th>Purpose  F1-score</th>\n",
       "      <th>Purpose  Support</th>\n",
       "      <th>Summary  Precision</th>\n",
       "      <th>Summary  Recall</th>\n",
       "      <th>Summary  F1-score</th>\n",
       "      <th>Summary  Support</th>\n",
       "      <th>Temporal  Precision</th>\n",
       "      <th>Temporal  Recall</th>\n",
       "      <th>Temporal  F1-score</th>\n",
       "      <th>Temporal  Support</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro avg  Precision</th>\n",
       "      <th>Macro avg  Recall</th>\n",
       "      <th>Macro avg  F1-score</th>\n",
       "      <th>Macro avg  Support</th>\n",
       "      <th>Weighted avg  Precision</th>\n",
       "      <th>Weighted avg  Recall</th>\n",
       "      <th>Weighted avg  F1-score</th>\n",
       "      <th>Weighted avg  Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.256500</td>\n",
       "      <td>1.223622</td>\n",
       "      <td>0.722593</td>\n",
       "      <td>0.955864</td>\n",
       "      <td>0.823018</td>\n",
       "      <td>793</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.112150</td>\n",
       "      <td>0.110092</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>85</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>147</td>\n",
       "      <td>0.633893</td>\n",
       "      <td>0.105547</td>\n",
       "      <td>0.102695</td>\n",
       "      <td>0.096468</td>\n",
       "      <td>1251</td>\n",
       "      <td>0.509548</td>\n",
       "      <td>0.633893</td>\n",
       "      <td>0.555582</td>\n",
       "      <td>1251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.995100</td>\n",
       "      <td>1.271319</td>\n",
       "      <td>0.841290</td>\n",
       "      <td>0.822194</td>\n",
       "      <td>0.831633</td>\n",
       "      <td>793</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>0.412844</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>0.635294</td>\n",
       "      <td>0.378947</td>\n",
       "      <td>85</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.396694</td>\n",
       "      <td>0.326531</td>\n",
       "      <td>0.358209</td>\n",
       "      <td>147</td>\n",
       "      <td>0.638689</td>\n",
       "      <td>0.149859</td>\n",
       "      <td>0.183072</td>\n",
       "      <td>0.159142</td>\n",
       "      <td>1251</td>\n",
       "      <td>0.623543</td>\n",
       "      <td>0.638689</td>\n",
       "      <td>0.624709</td>\n",
       "      <td>1251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.678400</td>\n",
       "      <td>1.434299</td>\n",
       "      <td>0.822542</td>\n",
       "      <td>0.865069</td>\n",
       "      <td>0.843270</td>\n",
       "      <td>793</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.335714</td>\n",
       "      <td>0.431193</td>\n",
       "      <td>0.377510</td>\n",
       "      <td>109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>0.339623</td>\n",
       "      <td>0.635294</td>\n",
       "      <td>0.442623</td>\n",
       "      <td>85</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.381356</td>\n",
       "      <td>0.306122</td>\n",
       "      <td>0.339623</td>\n",
       "      <td>147</td>\n",
       "      <td>0.665068</td>\n",
       "      <td>0.156603</td>\n",
       "      <td>0.186473</td>\n",
       "      <td>0.166919</td>\n",
       "      <td>1251</td>\n",
       "      <td>0.618542</td>\n",
       "      <td>0.665068</td>\n",
       "      <td>0.637417</td>\n",
       "      <td>1251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.555500</td>\n",
       "      <td>1.478074</td>\n",
       "      <td>0.839853</td>\n",
       "      <td>0.866330</td>\n",
       "      <td>0.852886</td>\n",
       "      <td>793</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.402985</td>\n",
       "      <td>0.495413</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>0.416107</td>\n",
       "      <td>0.729412</td>\n",
       "      <td>0.529915</td>\n",
       "      <td>85</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.465116</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.411290</td>\n",
       "      <td>0.346939</td>\n",
       "      <td>0.376384</td>\n",
       "      <td>147</td>\n",
       "      <td>0.691447</td>\n",
       "      <td>0.236529</td>\n",
       "      <td>0.246825</td>\n",
       "      <td>0.226099</td>\n",
       "      <td>1251</td>\n",
       "      <td>0.662233</td>\n",
       "      <td>0.691447</td>\n",
       "      <td>0.668524</td>\n",
       "      <td>1251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.364200</td>\n",
       "      <td>1.597566</td>\n",
       "      <td>0.841388</td>\n",
       "      <td>0.856242</td>\n",
       "      <td>0.848750</td>\n",
       "      <td>793</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.377358</td>\n",
       "      <td>0.550459</td>\n",
       "      <td>0.447761</td>\n",
       "      <td>109</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>14</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.163265</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>0.435185</td>\n",
       "      <td>0.552941</td>\n",
       "      <td>0.487047</td>\n",
       "      <td>85</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.465116</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.391608</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.386207</td>\n",
       "      <td>147</td>\n",
       "      <td>0.685052</td>\n",
       "      <td>0.275146</td>\n",
       "      <td>0.250605</td>\n",
       "      <td>0.242438</td>\n",
       "      <td>1251</td>\n",
       "      <td>0.670748</td>\n",
       "      <td>0.685052</td>\n",
       "      <td>0.669665</td>\n",
       "      <td>1251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-c906eaaad80e>:10: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n",
      "  if isinstance(v, collections.MutableMapping):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='626' max='626' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [626/626 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6914468425259792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9380' max='9380' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9380/9380 12:41, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>None  Precision</th>\n",
       "      <th>None  Recall</th>\n",
       "      <th>None  F1-score</th>\n",
       "      <th>None  Support</th>\n",
       "      <th>Attribution  Precision</th>\n",
       "      <th>Attribution  Recall</th>\n",
       "      <th>Attribution  F1-score</th>\n",
       "      <th>Attribution  Support</th>\n",
       "      <th>Causal  Precision</th>\n",
       "      <th>Causal  Recall</th>\n",
       "      <th>Causal  F1-score</th>\n",
       "      <th>Causal  Support</th>\n",
       "      <th>Conditional  Precision</th>\n",
       "      <th>Conditional  Recall</th>\n",
       "      <th>Conditional  F1-score</th>\n",
       "      <th>Conditional  Support</th>\n",
       "      <th>Contrast  Precision</th>\n",
       "      <th>Contrast  Recall</th>\n",
       "      <th>Contrast  F1-score</th>\n",
       "      <th>Contrast  Support</th>\n",
       "      <th>Description  Precision</th>\n",
       "      <th>Description  Recall</th>\n",
       "      <th>Description  F1-score</th>\n",
       "      <th>Description  Support</th>\n",
       "      <th>Equivalence  Precision</th>\n",
       "      <th>Equivalence  Recall</th>\n",
       "      <th>Equivalence  F1-score</th>\n",
       "      <th>Equivalence  Support</th>\n",
       "      <th>Fulfillment  Precision</th>\n",
       "      <th>Fulfillment  Recall</th>\n",
       "      <th>Fulfillment  F1-score</th>\n",
       "      <th>Fulfillment  Support</th>\n",
       "      <th>Identity  Precision</th>\n",
       "      <th>Identity  Recall</th>\n",
       "      <th>Identity  F1-score</th>\n",
       "      <th>Identity  Support</th>\n",
       "      <th>Purpose  Precision</th>\n",
       "      <th>Purpose  Recall</th>\n",
       "      <th>Purpose  F1-score</th>\n",
       "      <th>Purpose  Support</th>\n",
       "      <th>Summary  Precision</th>\n",
       "      <th>Summary  Recall</th>\n",
       "      <th>Summary  F1-score</th>\n",
       "      <th>Summary  Support</th>\n",
       "      <th>Temporal  Precision</th>\n",
       "      <th>Temporal  Recall</th>\n",
       "      <th>Temporal  F1-score</th>\n",
       "      <th>Temporal  Support</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro avg  Precision</th>\n",
       "      <th>Macro avg  Recall</th>\n",
       "      <th>Macro avg  F1-score</th>\n",
       "      <th>Macro avg  Support</th>\n",
       "      <th>Weighted avg  Precision</th>\n",
       "      <th>Weighted avg  Recall</th>\n",
       "      <th>Weighted avg  F1-score</th>\n",
       "      <th>Weighted avg  Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.212900</td>\n",
       "      <td>1.084501</td>\n",
       "      <td>0.721956</td>\n",
       "      <td>0.949559</td>\n",
       "      <td>0.820261</td>\n",
       "      <td>793</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.195122</td>\n",
       "      <td>0.293578</td>\n",
       "      <td>0.234432</td>\n",
       "      <td>109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>85</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.108844</td>\n",
       "      <td>0.167539</td>\n",
       "      <td>147</td>\n",
       "      <td>0.640288</td>\n",
       "      <td>0.106726</td>\n",
       "      <td>0.112665</td>\n",
       "      <td>0.101853</td>\n",
       "      <td>1251</td>\n",
       "      <td>0.517373</td>\n",
       "      <td>0.640288</td>\n",
       "      <td>0.560071</td>\n",
       "      <td>1251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.043100</td>\n",
       "      <td>1.064208</td>\n",
       "      <td>0.798165</td>\n",
       "      <td>0.877680</td>\n",
       "      <td>0.836036</td>\n",
       "      <td>793</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.324074</td>\n",
       "      <td>0.321101</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>0.305970</td>\n",
       "      <td>0.482353</td>\n",
       "      <td>0.374429</td>\n",
       "      <td>85</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.445255</td>\n",
       "      <td>0.414966</td>\n",
       "      <td>0.429577</td>\n",
       "      <td>147</td>\n",
       "      <td>0.665867</td>\n",
       "      <td>0.156122</td>\n",
       "      <td>0.174675</td>\n",
       "      <td>0.163552</td>\n",
       "      <td>1251</td>\n",
       "      <td>0.607297</td>\n",
       "      <td>0.665867</td>\n",
       "      <td>0.633983</td>\n",
       "      <td>1251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.887600</td>\n",
       "      <td>1.290893</td>\n",
       "      <td>0.871728</td>\n",
       "      <td>0.839849</td>\n",
       "      <td>0.855491</td>\n",
       "      <td>793</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.375887</td>\n",
       "      <td>0.486239</td>\n",
       "      <td>0.424000</td>\n",
       "      <td>109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>0.364780</td>\n",
       "      <td>0.682353</td>\n",
       "      <td>0.475410</td>\n",
       "      <td>85</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.422460</td>\n",
       "      <td>0.537415</td>\n",
       "      <td>0.473054</td>\n",
       "      <td>147</td>\n",
       "      <td>0.684253</td>\n",
       "      <td>0.169571</td>\n",
       "      <td>0.212155</td>\n",
       "      <td>0.185663</td>\n",
       "      <td>1251</td>\n",
       "      <td>0.659760</td>\n",
       "      <td>0.684253</td>\n",
       "      <td>0.667122</td>\n",
       "      <td>1251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.609800</td>\n",
       "      <td>1.543676</td>\n",
       "      <td>0.836735</td>\n",
       "      <td>0.878941</td>\n",
       "      <td>0.857319</td>\n",
       "      <td>793</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.367021</td>\n",
       "      <td>0.633028</td>\n",
       "      <td>0.464646</td>\n",
       "      <td>109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>0.404040</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>85</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.387597</td>\n",
       "      <td>0.340136</td>\n",
       "      <td>0.362319</td>\n",
       "      <td>147</td>\n",
       "      <td>0.685851</td>\n",
       "      <td>0.249616</td>\n",
       "      <td>0.201891</td>\n",
       "      <td>0.191740</td>\n",
       "      <td>1251</td>\n",
       "      <td>0.651364</td>\n",
       "      <td>0.685851</td>\n",
       "      <td>0.658956</td>\n",
       "      <td>1251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.506100</td>\n",
       "      <td>1.696877</td>\n",
       "      <td>0.843521</td>\n",
       "      <td>0.870113</td>\n",
       "      <td>0.856611</td>\n",
       "      <td>793</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.550459</td>\n",
       "      <td>0.422535</td>\n",
       "      <td>109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>0.493506</td>\n",
       "      <td>0.447059</td>\n",
       "      <td>0.469136</td>\n",
       "      <td>85</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.375796</td>\n",
       "      <td>0.401361</td>\n",
       "      <td>0.388158</td>\n",
       "      <td>147</td>\n",
       "      <td>0.685851</td>\n",
       "      <td>0.212973</td>\n",
       "      <td>0.234916</td>\n",
       "      <td>0.221687</td>\n",
       "      <td>1251</td>\n",
       "      <td>0.650259</td>\n",
       "      <td>0.685851</td>\n",
       "      <td>0.665676</td>\n",
       "      <td>1251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='626' max='626' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [626/626 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6858513189448441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9380' max='9380' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9380/9380 12:29, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>None  Precision</th>\n",
       "      <th>None  Recall</th>\n",
       "      <th>None  F1-score</th>\n",
       "      <th>None  Support</th>\n",
       "      <th>Attribution  Precision</th>\n",
       "      <th>Attribution  Recall</th>\n",
       "      <th>Attribution  F1-score</th>\n",
       "      <th>Attribution  Support</th>\n",
       "      <th>Causal  Precision</th>\n",
       "      <th>Causal  Recall</th>\n",
       "      <th>Causal  F1-score</th>\n",
       "      <th>Causal  Support</th>\n",
       "      <th>Conditional  Precision</th>\n",
       "      <th>Conditional  Recall</th>\n",
       "      <th>Conditional  F1-score</th>\n",
       "      <th>Conditional  Support</th>\n",
       "      <th>Contrast  Precision</th>\n",
       "      <th>Contrast  Recall</th>\n",
       "      <th>Contrast  F1-score</th>\n",
       "      <th>Contrast  Support</th>\n",
       "      <th>Description  Precision</th>\n",
       "      <th>Description  Recall</th>\n",
       "      <th>Description  F1-score</th>\n",
       "      <th>Description  Support</th>\n",
       "      <th>Equivalence  Precision</th>\n",
       "      <th>Equivalence  Recall</th>\n",
       "      <th>Equivalence  F1-score</th>\n",
       "      <th>Equivalence  Support</th>\n",
       "      <th>Fulfillment  Precision</th>\n",
       "      <th>Fulfillment  Recall</th>\n",
       "      <th>Fulfillment  F1-score</th>\n",
       "      <th>Fulfillment  Support</th>\n",
       "      <th>Identity  Precision</th>\n",
       "      <th>Identity  Recall</th>\n",
       "      <th>Identity  F1-score</th>\n",
       "      <th>Identity  Support</th>\n",
       "      <th>Purpose  Precision</th>\n",
       "      <th>Purpose  Recall</th>\n",
       "      <th>Purpose  F1-score</th>\n",
       "      <th>Purpose  Support</th>\n",
       "      <th>Summary  Precision</th>\n",
       "      <th>Summary  Recall</th>\n",
       "      <th>Summary  F1-score</th>\n",
       "      <th>Summary  Support</th>\n",
       "      <th>Temporal  Precision</th>\n",
       "      <th>Temporal  Recall</th>\n",
       "      <th>Temporal  F1-score</th>\n",
       "      <th>Temporal  Support</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro avg  Precision</th>\n",
       "      <th>Macro avg  Recall</th>\n",
       "      <th>Macro avg  F1-score</th>\n",
       "      <th>Macro avg  Support</th>\n",
       "      <th>Weighted avg  Precision</th>\n",
       "      <th>Weighted avg  Recall</th>\n",
       "      <th>Weighted avg  F1-score</th>\n",
       "      <th>Weighted avg  Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.298300</td>\n",
       "      <td>1.241064</td>\n",
       "      <td>0.669795</td>\n",
       "      <td>0.989912</td>\n",
       "      <td>0.798982</td>\n",
       "      <td>793</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>0.294872</td>\n",
       "      <td>0.270588</td>\n",
       "      <td>0.282209</td>\n",
       "      <td>85</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>148</td>\n",
       "      <td>0.646400</td>\n",
       "      <td>0.080389</td>\n",
       "      <td>0.105042</td>\n",
       "      <td>0.090099</td>\n",
       "      <td>1250</td>\n",
       "      <td>0.444969</td>\n",
       "      <td>0.646400</td>\n",
       "      <td>0.526064</td>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.075800</td>\n",
       "      <td>1.309541</td>\n",
       "      <td>0.808962</td>\n",
       "      <td>0.865069</td>\n",
       "      <td>0.836076</td>\n",
       "      <td>793</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.291139</td>\n",
       "      <td>0.212963</td>\n",
       "      <td>0.245989</td>\n",
       "      <td>108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>0.276316</td>\n",
       "      <td>0.741176</td>\n",
       "      <td>0.402556</td>\n",
       "      <td>85</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.202703</td>\n",
       "      <td>0.246914</td>\n",
       "      <td>148</td>\n",
       "      <td>0.641600</td>\n",
       "      <td>0.141017</td>\n",
       "      <td>0.168493</td>\n",
       "      <td>0.144295</td>\n",
       "      <td>1250</td>\n",
       "      <td>0.594539</td>\n",
       "      <td>0.641600</td>\n",
       "      <td>0.608268</td>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.857900</td>\n",
       "      <td>1.400006</td>\n",
       "      <td>0.836735</td>\n",
       "      <td>0.827238</td>\n",
       "      <td>0.831959</td>\n",
       "      <td>793</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.296610</td>\n",
       "      <td>0.324074</td>\n",
       "      <td>0.309735</td>\n",
       "      <td>108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.458824</td>\n",
       "      <td>0.426230</td>\n",
       "      <td>85</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.308000</td>\n",
       "      <td>0.520270</td>\n",
       "      <td>0.386935</td>\n",
       "      <td>148</td>\n",
       "      <td>0.645600</td>\n",
       "      <td>0.153275</td>\n",
       "      <td>0.177534</td>\n",
       "      <td>0.162905</td>\n",
       "      <td>1250</td>\n",
       "      <td>0.619980</td>\n",
       "      <td>0.645600</td>\n",
       "      <td>0.629353</td>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.604800</td>\n",
       "      <td>1.723444</td>\n",
       "      <td>0.832099</td>\n",
       "      <td>0.849937</td>\n",
       "      <td>0.840923</td>\n",
       "      <td>793</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.393443</td>\n",
       "      <td>108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>41</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>0.404959</td>\n",
       "      <td>0.576471</td>\n",
       "      <td>0.475728</td>\n",
       "      <td>85</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.345679</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.361290</td>\n",
       "      <td>148</td>\n",
       "      <td>0.666400</td>\n",
       "      <td>0.204015</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>0.199387</td>\n",
       "      <td>1250</td>\n",
       "      <td>0.638403</td>\n",
       "      <td>0.666400</td>\n",
       "      <td>0.648472</td>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.424300</td>\n",
       "      <td>1.870731</td>\n",
       "      <td>0.852523</td>\n",
       "      <td>0.831021</td>\n",
       "      <td>0.841635</td>\n",
       "      <td>793</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.327778</td>\n",
       "      <td>0.546296</td>\n",
       "      <td>0.409722</td>\n",
       "      <td>108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.121951</td>\n",
       "      <td>0.204082</td>\n",
       "      <td>41</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>0.473118</td>\n",
       "      <td>0.517647</td>\n",
       "      <td>0.494382</td>\n",
       "      <td>85</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.367347</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.347305</td>\n",
       "      <td>0.391892</td>\n",
       "      <td>0.368254</td>\n",
       "      <td>148</td>\n",
       "      <td>0.667200</td>\n",
       "      <td>0.244672</td>\n",
       "      <td>0.238234</td>\n",
       "      <td>0.223785</td>\n",
       "      <td>1250</td>\n",
       "      <td>0.667919</td>\n",
       "      <td>0.667200</td>\n",
       "      <td>0.659124</td>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9380' max='9380' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9380/9380 11:22, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>None  Precision</th>\n",
       "      <th>None  Recall</th>\n",
       "      <th>None  F1-score</th>\n",
       "      <th>None  Support</th>\n",
       "      <th>Attribution  Precision</th>\n",
       "      <th>Attribution  Recall</th>\n",
       "      <th>Attribution  F1-score</th>\n",
       "      <th>Attribution  Support</th>\n",
       "      <th>Causal  Precision</th>\n",
       "      <th>Causal  Recall</th>\n",
       "      <th>Causal  F1-score</th>\n",
       "      <th>Causal  Support</th>\n",
       "      <th>Conditional  Precision</th>\n",
       "      <th>Conditional  Recall</th>\n",
       "      <th>Conditional  F1-score</th>\n",
       "      <th>Conditional  Support</th>\n",
       "      <th>Contrast  Precision</th>\n",
       "      <th>Contrast  Recall</th>\n",
       "      <th>Contrast  F1-score</th>\n",
       "      <th>Contrast  Support</th>\n",
       "      <th>Description  Precision</th>\n",
       "      <th>Description  Recall</th>\n",
       "      <th>Description  F1-score</th>\n",
       "      <th>Description  Support</th>\n",
       "      <th>Equivalence  Precision</th>\n",
       "      <th>Equivalence  Recall</th>\n",
       "      <th>Equivalence  F1-score</th>\n",
       "      <th>Equivalence  Support</th>\n",
       "      <th>Fulfillment  Precision</th>\n",
       "      <th>Fulfillment  Recall</th>\n",
       "      <th>Fulfillment  F1-score</th>\n",
       "      <th>Fulfillment  Support</th>\n",
       "      <th>Identity  Precision</th>\n",
       "      <th>Identity  Recall</th>\n",
       "      <th>Identity  F1-score</th>\n",
       "      <th>Identity  Support</th>\n",
       "      <th>Purpose  Precision</th>\n",
       "      <th>Purpose  Recall</th>\n",
       "      <th>Purpose  F1-score</th>\n",
       "      <th>Purpose  Support</th>\n",
       "      <th>Summary  Precision</th>\n",
       "      <th>Summary  Recall</th>\n",
       "      <th>Summary  F1-score</th>\n",
       "      <th>Summary  Support</th>\n",
       "      <th>Temporal  Precision</th>\n",
       "      <th>Temporal  Recall</th>\n",
       "      <th>Temporal  F1-score</th>\n",
       "      <th>Temporal  Support</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro avg  Precision</th>\n",
       "      <th>Macro avg  Recall</th>\n",
       "      <th>Macro avg  F1-score</th>\n",
       "      <th>Macro avg  Support</th>\n",
       "      <th>Weighted avg  Precision</th>\n",
       "      <th>Weighted avg  Recall</th>\n",
       "      <th>Weighted avg  F1-score</th>\n",
       "      <th>Weighted avg  Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.338100</td>\n",
       "      <td>1.201117</td>\n",
       "      <td>0.739979</td>\n",
       "      <td>0.907945</td>\n",
       "      <td>0.815402</td>\n",
       "      <td>793</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.009259</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14</td>\n",
       "      <td>0.202381</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.268775</td>\n",
       "      <td>85</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.381443</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.302041</td>\n",
       "      <td>148</td>\n",
       "      <td>0.633600</td>\n",
       "      <td>0.117261</td>\n",
       "      <td>0.130600</td>\n",
       "      <td>0.116907</td>\n",
       "      <td>1250</td>\n",
       "      <td>0.535568</td>\n",
       "      <td>0.633600</td>\n",
       "      <td>0.572769</td>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.145100</td>\n",
       "      <td>1.275135</td>\n",
       "      <td>0.827543</td>\n",
       "      <td>0.841110</td>\n",
       "      <td>0.834271</td>\n",
       "      <td>793</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.324074</td>\n",
       "      <td>0.299145</td>\n",
       "      <td>108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14</td>\n",
       "      <td>0.243478</td>\n",
       "      <td>0.329412</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>85</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.384236</td>\n",
       "      <td>0.527027</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>148</td>\n",
       "      <td>0.646400</td>\n",
       "      <td>0.144420</td>\n",
       "      <td>0.168469</td>\n",
       "      <td>0.154822</td>\n",
       "      <td>1250</td>\n",
       "      <td>0.611044</td>\n",
       "      <td>0.646400</td>\n",
       "      <td>0.626770</td>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.918500</td>\n",
       "      <td>1.364766</td>\n",
       "      <td>0.841902</td>\n",
       "      <td>0.825977</td>\n",
       "      <td>0.833864</td>\n",
       "      <td>793</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.335484</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.395437</td>\n",
       "      <td>108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14</td>\n",
       "      <td>0.301205</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.398406</td>\n",
       "      <td>85</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.403974</td>\n",
       "      <td>0.412162</td>\n",
       "      <td>0.408027</td>\n",
       "      <td>148</td>\n",
       "      <td>0.654400</td>\n",
       "      <td>0.156880</td>\n",
       "      <td>0.192321</td>\n",
       "      <td>0.169645</td>\n",
       "      <td>1250</td>\n",
       "      <td>0.631401</td>\n",
       "      <td>0.654400</td>\n",
       "      <td>0.638571</td>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.756500</td>\n",
       "      <td>1.570095</td>\n",
       "      <td>0.835411</td>\n",
       "      <td>0.844893</td>\n",
       "      <td>0.840125</td>\n",
       "      <td>793</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.306878</td>\n",
       "      <td>0.537037</td>\n",
       "      <td>0.390572</td>\n",
       "      <td>108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14</td>\n",
       "      <td>0.355372</td>\n",
       "      <td>0.505882</td>\n",
       "      <td>0.417476</td>\n",
       "      <td>85</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.405797</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.391608</td>\n",
       "      <td>148</td>\n",
       "      <td>0.661600</td>\n",
       "      <td>0.158622</td>\n",
       "      <td>0.188849</td>\n",
       "      <td>0.169982</td>\n",
       "      <td>1250</td>\n",
       "      <td>0.628711</td>\n",
       "      <td>0.661600</td>\n",
       "      <td>0.641476</td>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.561800</td>\n",
       "      <td>1.743830</td>\n",
       "      <td>0.832099</td>\n",
       "      <td>0.849937</td>\n",
       "      <td>0.840923</td>\n",
       "      <td>793</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.319767</td>\n",
       "      <td>0.509259</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.517647</td>\n",
       "      <td>0.427184</td>\n",
       "      <td>85</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.371622</td>\n",
       "      <td>0.375427</td>\n",
       "      <td>148</td>\n",
       "      <td>0.664000</td>\n",
       "      <td>0.241234</td>\n",
       "      <td>0.195705</td>\n",
       "      <td>0.184851</td>\n",
       "      <td>1250</td>\n",
       "      <td>0.641149</td>\n",
       "      <td>0.664000</td>\n",
       "      <td>0.643833</td>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 00:12]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.664\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "num_labels = len(labels)\n",
    "models = []\n",
    "\n",
    "for i in range(num_folds):\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)\n",
    "    # import Fold data\n",
    "    train_origin, train_target, train_labels, test_origin, test_target, test_labels = import_fold(\"data/export-ohnetime\", i)\n",
    "    # tokenize\n",
    "    train_encodings = tokenizer(train_origin, train_target, truncation=True, padding=True, return_token_type_ids=True)\n",
    "    test_encodings = tokenizer(test_origin, test_target, truncation=True, padding=True, return_token_type_ids=True)\n",
    "    # dataset creation\n",
    "    train_dataset = SemanticDataset(train_encodings, train_labels)\n",
    "    test_dataset = SemanticDataset(test_encodings, test_labels)\n",
    "    # create Trainer\n",
    "    trainer = Trainer(\n",
    "        model,\n",
    "        args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "    # train & evaluate\n",
    "    trainer.train()\n",
    "    ev = trainer.evaluate(test_dataset)\n",
    "    acc = ev[\"eval_accuracy\"]\n",
    "    print(f\"Accuracy: {acc}\")\n",
    "    result.append(ev)\n",
    "    models.append(trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e39bf6",
   "metadata": {},
   "source": [
    "## Interpret evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be62939",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a264f9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(data):\n",
    "    \"\"\"Return the sample arithmetic mean of data.\"\"\"\n",
    "    n = len(data)\n",
    "    if n < 1:\n",
    "        raise ValueError('mean requires at least one data point')\n",
    "    return sum(data)/n # in Python 2 use sum(data)/float(n)\n",
    "\n",
    "def _ss(data):\n",
    "    \"\"\"Return sum of square deviations of sequence data.\"\"\"\n",
    "    c = mean(data)\n",
    "    ss = sum((x-c)**2 for x in data)\n",
    "    return ss\n",
    "\n",
    "def stddev(data, ddof=0):\n",
    "    \"\"\"Calculates the population standard deviation\n",
    "    by default; specify ddof=1 to compute the sample\n",
    "    standard deviation.\"\"\"\n",
    "    n = len(data)\n",
    "    if n < 2:\n",
    "        raise ValueError('variance requires at least two data points')\n",
    "    ss = _ss(data)\n",
    "    pvar = ss/(n-ddof)\n",
    "    return pvar**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25d41df",
   "metadata": {},
   "source": [
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13df0f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'eval_loss': 1.478074312210083,\n",
       "  'eval_none__precision': 0.8398533007334963,\n",
       "  'eval_none__recall': 0.8663303909205549,\n",
       "  'eval_none__f1-score': 0.8528864059590316,\n",
       "  'eval_none__support': 793,\n",
       "  'eval_attribution__precision': 0.0,\n",
       "  'eval_attribution__recall': 0.0,\n",
       "  'eval_attribution__f1-score': 0.0,\n",
       "  'eval_attribution__support': 6,\n",
       "  'eval_causal__precision': 0.40298507462686567,\n",
       "  'eval_causal__recall': 0.4954128440366973,\n",
       "  'eval_causal__f1-score': 0.4444444444444445,\n",
       "  'eval_causal__support': 109,\n",
       "  'eval_conditional__precision': 0.0,\n",
       "  'eval_conditional__recall': 0.0,\n",
       "  'eval_conditional__f1-score': 0.0,\n",
       "  'eval_conditional__support': 14,\n",
       "  'eval_contrast__precision': 0.3333333333333333,\n",
       "  'eval_contrast__recall': 0.023809523809523808,\n",
       "  'eval_contrast__f1-score': 0.044444444444444446,\n",
       "  'eval_contrast__support': 42,\n",
       "  'eval_description__precision': 0.0,\n",
       "  'eval_description__recall': 0.0,\n",
       "  'eval_description__f1-score': 0.0,\n",
       "  'eval_description__support': 13,\n",
       "  'eval_equivalence__precision': 0.4161073825503356,\n",
       "  'eval_equivalence__recall': 0.7294117647058823,\n",
       "  'eval_equivalence__f1-score': 0.5299145299145299,\n",
       "  'eval_equivalence__support': 85,\n",
       "  'eval_fulfillment__precision': 0.0,\n",
       "  'eval_fulfillment__recall': 0.0,\n",
       "  'eval_fulfillment__f1-score': 0.0,\n",
       "  'eval_fulfillment__support': 11,\n",
       "  'eval_identity__precision': 0.43478260869565216,\n",
       "  'eval_identity__recall': 0.5,\n",
       "  'eval_identity__f1-score': 0.46511627906976744,\n",
       "  'eval_identity__support': 20,\n",
       "  'eval_purpose__precision': 0.0,\n",
       "  'eval_purpose__recall': 0.0,\n",
       "  'eval_purpose__f1-score': 0.0,\n",
       "  'eval_purpose__support': 5,\n",
       "  'eval_summary__precision': 0.0,\n",
       "  'eval_summary__recall': 0.0,\n",
       "  'eval_summary__f1-score': 0.0,\n",
       "  'eval_summary__support': 6,\n",
       "  'eval_temporal__precision': 0.4112903225806452,\n",
       "  'eval_temporal__recall': 0.3469387755102041,\n",
       "  'eval_temporal__f1-score': 0.37638376383763844,\n",
       "  'eval_temporal__support': 147,\n",
       "  'eval_accuracy': 0.6914468425259792,\n",
       "  'eval_macro avg__precision': 0.23652933521002736,\n",
       "  'eval_macro avg__recall': 0.24682527491523854,\n",
       "  'eval_macro avg__f1-score': 0.22609915563915473,\n",
       "  'eval_macro avg__support': 1251,\n",
       "  'eval_weighted avg__precision': 0.6622330117714127,\n",
       "  'eval_weighted avg__recall': 0.6914468425259792,\n",
       "  'eval_weighted avg__f1-score': 0.6685239847680946,\n",
       "  'eval_weighted avg__support': 1251,\n",
       "  'eval_runtime': 9.7601,\n",
       "  'eval_samples_per_second': 128.175,\n",
       "  'epoch': 5.0},\n",
       " {'eval_loss': 1.5436761379241943,\n",
       "  'eval_none__precision': 0.8367346938775511,\n",
       "  'eval_none__recall': 0.8789407313997478,\n",
       "  'eval_none__f1-score': 0.8573185731857319,\n",
       "  'eval_none__support': 793,\n",
       "  'eval_attribution__precision': 0.0,\n",
       "  'eval_attribution__recall': 0.0,\n",
       "  'eval_attribution__f1-score': 0.0,\n",
       "  'eval_attribution__support': 6,\n",
       "  'eval_causal__precision': 0.3670212765957447,\n",
       "  'eval_causal__recall': 0.6330275229357798,\n",
       "  'eval_causal__f1-score': 0.4646464646464646,\n",
       "  'eval_causal__support': 109,\n",
       "  'eval_conditional__precision': 0.0,\n",
       "  'eval_conditional__recall': 0.0,\n",
       "  'eval_conditional__f1-score': 0.0,\n",
       "  'eval_conditional__support': 14,\n",
       "  'eval_contrast__precision': 0.0,\n",
       "  'eval_contrast__recall': 0.0,\n",
       "  'eval_contrast__f1-score': 0.0,\n",
       "  'eval_contrast__support': 41,\n",
       "  'eval_description__precision': 0.0,\n",
       "  'eval_description__recall': 0.0,\n",
       "  'eval_description__f1-score': 0.0,\n",
       "  'eval_description__support': 13,\n",
       "  'eval_equivalence__precision': 0.40404040404040403,\n",
       "  'eval_equivalence__recall': 0.47058823529411764,\n",
       "  'eval_equivalence__f1-score': 0.43478260869565216,\n",
       "  'eval_equivalence__support': 85,\n",
       "  'eval_fulfillment__precision': 0.0,\n",
       "  'eval_fulfillment__recall': 0.0,\n",
       "  'eval_fulfillment__f1-score': 0.0,\n",
       "  'eval_fulfillment__support': 11,\n",
       "  'eval_identity__precision': 1.0,\n",
       "  'eval_identity__recall': 0.1,\n",
       "  'eval_identity__f1-score': 0.18181818181818182,\n",
       "  'eval_identity__support': 20,\n",
       "  'eval_purpose__precision': 0.0,\n",
       "  'eval_purpose__recall': 0.0,\n",
       "  'eval_purpose__f1-score': 0.0,\n",
       "  'eval_purpose__support': 6,\n",
       "  'eval_summary__precision': 0.0,\n",
       "  'eval_summary__recall': 0.0,\n",
       "  'eval_summary__f1-score': 0.0,\n",
       "  'eval_summary__support': 6,\n",
       "  'eval_temporal__precision': 0.3875968992248062,\n",
       "  'eval_temporal__recall': 0.3401360544217687,\n",
       "  'eval_temporal__f1-score': 0.36231884057971014,\n",
       "  'eval_temporal__support': 147,\n",
       "  'eval_accuracy': 0.6858513189448441,\n",
       "  'eval_macro avg__precision': 0.24961610614487548,\n",
       "  'eval_macro avg__recall': 0.20189104533761784,\n",
       "  'eval_macro avg__f1-score': 0.19174038907714505,\n",
       "  'eval_macro avg__support': 1251,\n",
       "  'eval_weighted avg__precision': 0.6513637969011311,\n",
       "  'eval_weighted avg__recall': 0.6858513189448441,\n",
       "  'eval_weighted avg__f1-score': 0.6589559137677551,\n",
       "  'eval_weighted avg__support': 1251,\n",
       "  'eval_runtime': 9.601,\n",
       "  'eval_samples_per_second': 130.299,\n",
       "  'epoch': 5.0},\n",
       " {'eval_loss': 1.8707308769226074,\n",
       "  'eval_none__precision': 0.8525226390685641,\n",
       "  'eval_none__recall': 0.8310214375788146,\n",
       "  'eval_none__f1-score': 0.8416347381864625,\n",
       "  'eval_none__support': 793,\n",
       "  'eval_attribution__precision': 0.0,\n",
       "  'eval_attribution__recall': 0.0,\n",
       "  'eval_attribution__f1-score': 0.0,\n",
       "  'eval_attribution__support': 5,\n",
       "  'eval_causal__precision': 0.3277777777777778,\n",
       "  'eval_causal__recall': 0.5462962962962963,\n",
       "  'eval_causal__f1-score': 0.40972222222222227,\n",
       "  'eval_causal__support': 108,\n",
       "  'eval_conditional__precision': 0.0,\n",
       "  'eval_conditional__recall': 0.0,\n",
       "  'eval_conditional__f1-score': 0.0,\n",
       "  'eval_conditional__support': 14,\n",
       "  'eval_contrast__precision': 0.625,\n",
       "  'eval_contrast__recall': 0.12195121951219512,\n",
       "  'eval_contrast__f1-score': 0.20408163265306123,\n",
       "  'eval_contrast__support': 41,\n",
       "  'eval_description__precision': 0.0,\n",
       "  'eval_description__recall': 0.0,\n",
       "  'eval_description__f1-score': 0.0,\n",
       "  'eval_description__support': 13,\n",
       "  'eval_equivalence__precision': 0.4731182795698925,\n",
       "  'eval_equivalence__recall': 0.5176470588235295,\n",
       "  'eval_equivalence__f1-score': 0.4943820224719101,\n",
       "  'eval_equivalence__support': 85,\n",
       "  'eval_fulfillment__precision': 0.0,\n",
       "  'eval_fulfillment__recall': 0.0,\n",
       "  'eval_fulfillment__f1-score': 0.0,\n",
       "  'eval_fulfillment__support': 11,\n",
       "  'eval_identity__precision': 0.3103448275862069,\n",
       "  'eval_identity__recall': 0.45,\n",
       "  'eval_identity__f1-score': 0.3673469387755102,\n",
       "  'eval_identity__support': 20,\n",
       "  'eval_purpose__precision': 0.0,\n",
       "  'eval_purpose__recall': 0.0,\n",
       "  'eval_purpose__f1-score': 0.0,\n",
       "  'eval_purpose__support': 6,\n",
       "  'eval_summary__precision': 0.0,\n",
       "  'eval_summary__recall': 0.0,\n",
       "  'eval_summary__f1-score': 0.0,\n",
       "  'eval_summary__support': 6,\n",
       "  'eval_temporal__precision': 0.3473053892215569,\n",
       "  'eval_temporal__recall': 0.3918918918918919,\n",
       "  'eval_temporal__f1-score': 0.3682539682539682,\n",
       "  'eval_temporal__support': 148,\n",
       "  'eval_accuracy': 0.6672,\n",
       "  'eval_macro avg__precision': 0.24467240943533317,\n",
       "  'eval_macro avg__recall': 0.23823399200856063,\n",
       "  'eval_macro avg__f1-score': 0.2237851268802612,\n",
       "  'eval_macro avg__support': 1250,\n",
       "  'eval_weighted avg__precision': 0.6679188805610614,\n",
       "  'eval_weighted avg__recall': 0.6672,\n",
       "  'eval_weighted avg__f1-score': 0.6591237538462801,\n",
       "  'eval_weighted avg__support': 1250,\n",
       "  'eval_runtime': 9.7479,\n",
       "  'eval_samples_per_second': 128.232,\n",
       "  'epoch': 5.0},\n",
       " {'eval_loss': 1.7438303232192993,\n",
       "  'eval_none__precision': 0.8320987654320988,\n",
       "  'eval_none__recall': 0.849936948297604,\n",
       "  'eval_none__f1-score': 0.8409232688708672,\n",
       "  'eval_none__support': 793,\n",
       "  'eval_attribution__precision': 0.0,\n",
       "  'eval_attribution__recall': 0.0,\n",
       "  'eval_attribution__f1-score': 0.0,\n",
       "  'eval_attribution__support': 6,\n",
       "  'eval_causal__precision': 0.31976744186046513,\n",
       "  'eval_causal__recall': 0.5092592592592593,\n",
       "  'eval_causal__f1-score': 0.39285714285714285,\n",
       "  'eval_causal__support': 108,\n",
       "  'eval_conditional__precision': 0.0,\n",
       "  'eval_conditional__recall': 0.0,\n",
       "  'eval_conditional__f1-score': 0.0,\n",
       "  'eval_conditional__support': 14,\n",
       "  'eval_contrast__precision': 0.0,\n",
       "  'eval_contrast__recall': 0.0,\n",
       "  'eval_contrast__f1-score': 0.0,\n",
       "  'eval_contrast__support': 41,\n",
       "  'eval_description__precision': 0.0,\n",
       "  'eval_description__recall': 0.0,\n",
       "  'eval_description__f1-score': 0.0,\n",
       "  'eval_description__support': 14,\n",
       "  'eval_equivalence__precision': 0.36363636363636365,\n",
       "  'eval_equivalence__recall': 0.5176470588235295,\n",
       "  'eval_equivalence__f1-score': 0.4271844660194175,\n",
       "  'eval_equivalence__support': 85,\n",
       "  'eval_fulfillment__precision': 0.0,\n",
       "  'eval_fulfillment__recall': 0.0,\n",
       "  'eval_fulfillment__f1-score': 0.0,\n",
       "  'eval_fulfillment__support': 10,\n",
       "  'eval_identity__precision': 1.0,\n",
       "  'eval_identity__recall': 0.1,\n",
       "  'eval_identity__f1-score': 0.18181818181818182,\n",
       "  'eval_identity__support': 20,\n",
       "  'eval_purpose__precision': 0.0,\n",
       "  'eval_purpose__recall': 0.0,\n",
       "  'eval_purpose__f1-score': 0.0,\n",
       "  'eval_purpose__support': 5,\n",
       "  'eval_summary__precision': 0.0,\n",
       "  'eval_summary__recall': 0.0,\n",
       "  'eval_summary__f1-score': 0.0,\n",
       "  'eval_summary__support': 6,\n",
       "  'eval_temporal__precision': 0.3793103448275862,\n",
       "  'eval_temporal__recall': 0.3716216216216216,\n",
       "  'eval_temporal__f1-score': 0.37542662116040953,\n",
       "  'eval_temporal__support': 148,\n",
       "  'eval_accuracy': 0.664,\n",
       "  'eval_macro avg__precision': 0.24123440964637619,\n",
       "  'eval_macro avg__recall': 0.1957054073335012,\n",
       "  'eval_macro avg__f1-score': 0.18485080672716825,\n",
       "  'eval_macro avg__support': 1250,\n",
       "  'eval_weighted avg__precision': 0.6411489813217266,\n",
       "  'eval_weighted avg__recall': 0.664,\n",
       "  'eval_weighted avg__f1-score': 0.643832725458339,\n",
       "  'eval_weighted avg__support': 1250,\n",
       "  'eval_runtime': 12.4092,\n",
       "  'eval_samples_per_second': 100.731,\n",
       "  'epoch': 5.0}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70dad3cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_none__precision</th>\n",
       "      <th>eval_none__recall</th>\n",
       "      <th>eval_none__f1-score</th>\n",
       "      <th>eval_none__support</th>\n",
       "      <th>eval_attribution__precision</th>\n",
       "      <th>eval_attribution__recall</th>\n",
       "      <th>eval_attribution__f1-score</th>\n",
       "      <th>eval_attribution__support</th>\n",
       "      <th>eval_causal__precision</th>\n",
       "      <th>eval_causal__recall</th>\n",
       "      <th>eval_causal__f1-score</th>\n",
       "      <th>eval_causal__support</th>\n",
       "      <th>eval_conditional__precision</th>\n",
       "      <th>eval_conditional__recall</th>\n",
       "      <th>eval_conditional__f1-score</th>\n",
       "      <th>eval_conditional__support</th>\n",
       "      <th>eval_contrast__precision</th>\n",
       "      <th>eval_contrast__recall</th>\n",
       "      <th>eval_contrast__f1-score</th>\n",
       "      <th>eval_contrast__support</th>\n",
       "      <th>eval_description__precision</th>\n",
       "      <th>eval_description__recall</th>\n",
       "      <th>eval_description__f1-score</th>\n",
       "      <th>eval_description__support</th>\n",
       "      <th>eval_equivalence__precision</th>\n",
       "      <th>eval_equivalence__recall</th>\n",
       "      <th>eval_equivalence__f1-score</th>\n",
       "      <th>eval_equivalence__support</th>\n",
       "      <th>eval_fulfillment__precision</th>\n",
       "      <th>eval_fulfillment__recall</th>\n",
       "      <th>eval_fulfillment__f1-score</th>\n",
       "      <th>eval_fulfillment__support</th>\n",
       "      <th>eval_identity__precision</th>\n",
       "      <th>eval_identity__recall</th>\n",
       "      <th>eval_identity__f1-score</th>\n",
       "      <th>eval_identity__support</th>\n",
       "      <th>eval_purpose__precision</th>\n",
       "      <th>eval_purpose__recall</th>\n",
       "      <th>eval_purpose__f1-score</th>\n",
       "      <th>eval_purpose__support</th>\n",
       "      <th>eval_summary__precision</th>\n",
       "      <th>eval_summary__recall</th>\n",
       "      <th>eval_summary__f1-score</th>\n",
       "      <th>eval_summary__support</th>\n",
       "      <th>eval_temporal__precision</th>\n",
       "      <th>eval_temporal__recall</th>\n",
       "      <th>eval_temporal__f1-score</th>\n",
       "      <th>eval_temporal__support</th>\n",
       "      <th>eval_accuracy</th>\n",
       "      <th>eval_macro avg__precision</th>\n",
       "      <th>eval_macro avg__recall</th>\n",
       "      <th>eval_macro avg__f1-score</th>\n",
       "      <th>eval_macro avg__support</th>\n",
       "      <th>eval_weighted avg__precision</th>\n",
       "      <th>eval_weighted avg__recall</th>\n",
       "      <th>eval_weighted avg__f1-score</th>\n",
       "      <th>eval_weighted avg__support</th>\n",
       "      <th>eval_runtime</th>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.478074</td>\n",
       "      <td>0.839853</td>\n",
       "      <td>0.866330</td>\n",
       "      <td>0.852886</td>\n",
       "      <td>793.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0.402985</td>\n",
       "      <td>0.495413</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>109.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>42.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.00</td>\n",
       "      <td>0.416107</td>\n",
       "      <td>0.729412</td>\n",
       "      <td>0.529915</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.00</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.465116</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.411290</td>\n",
       "      <td>0.346939</td>\n",
       "      <td>0.376384</td>\n",
       "      <td>147.00000</td>\n",
       "      <td>0.691447</td>\n",
       "      <td>0.236529</td>\n",
       "      <td>0.246825</td>\n",
       "      <td>0.226099</td>\n",
       "      <td>1251.00000</td>\n",
       "      <td>0.662233</td>\n",
       "      <td>0.691447</td>\n",
       "      <td>0.668524</td>\n",
       "      <td>1251.00000</td>\n",
       "      <td>9.76010</td>\n",
       "      <td>128.175000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.543676</td>\n",
       "      <td>0.836735</td>\n",
       "      <td>0.878941</td>\n",
       "      <td>0.857319</td>\n",
       "      <td>793.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0.367021</td>\n",
       "      <td>0.633028</td>\n",
       "      <td>0.464646</td>\n",
       "      <td>109.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.00</td>\n",
       "      <td>0.404040</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.387597</td>\n",
       "      <td>0.340136</td>\n",
       "      <td>0.362319</td>\n",
       "      <td>147.00000</td>\n",
       "      <td>0.685851</td>\n",
       "      <td>0.249616</td>\n",
       "      <td>0.201891</td>\n",
       "      <td>0.191740</td>\n",
       "      <td>1251.00000</td>\n",
       "      <td>0.651364</td>\n",
       "      <td>0.685851</td>\n",
       "      <td>0.658956</td>\n",
       "      <td>1251.00000</td>\n",
       "      <td>9.60100</td>\n",
       "      <td>130.299000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.870731</td>\n",
       "      <td>0.852523</td>\n",
       "      <td>0.831021</td>\n",
       "      <td>0.841635</td>\n",
       "      <td>793.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.327778</td>\n",
       "      <td>0.546296</td>\n",
       "      <td>0.409722</td>\n",
       "      <td>108.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.121951</td>\n",
       "      <td>0.204082</td>\n",
       "      <td>41.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.00</td>\n",
       "      <td>0.473118</td>\n",
       "      <td>0.517647</td>\n",
       "      <td>0.494382</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.00</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.367347</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.347305</td>\n",
       "      <td>0.391892</td>\n",
       "      <td>0.368254</td>\n",
       "      <td>148.00000</td>\n",
       "      <td>0.667200</td>\n",
       "      <td>0.244672</td>\n",
       "      <td>0.238234</td>\n",
       "      <td>0.223785</td>\n",
       "      <td>1250.00000</td>\n",
       "      <td>0.667919</td>\n",
       "      <td>0.667200</td>\n",
       "      <td>0.659124</td>\n",
       "      <td>1250.00000</td>\n",
       "      <td>9.74790</td>\n",
       "      <td>128.232000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.743830</td>\n",
       "      <td>0.832099</td>\n",
       "      <td>0.849937</td>\n",
       "      <td>0.840923</td>\n",
       "      <td>793.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0.319767</td>\n",
       "      <td>0.509259</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>108.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.00</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.517647</td>\n",
       "      <td>0.427184</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.371622</td>\n",
       "      <td>0.375427</td>\n",
       "      <td>148.00000</td>\n",
       "      <td>0.664000</td>\n",
       "      <td>0.241234</td>\n",
       "      <td>0.195705</td>\n",
       "      <td>0.184851</td>\n",
       "      <td>1250.00000</td>\n",
       "      <td>0.641149</td>\n",
       "      <td>0.664000</td>\n",
       "      <td>0.643833</td>\n",
       "      <td>1250.00000</td>\n",
       "      <td>12.40920</td>\n",
       "      <td>100.731000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg</th>\n",
       "      <td>1.659078</td>\n",
       "      <td>0.840302</td>\n",
       "      <td>0.856557</td>\n",
       "      <td>0.848191</td>\n",
       "      <td>793.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.75</td>\n",
       "      <td>0.354388</td>\n",
       "      <td>0.545999</td>\n",
       "      <td>0.427918</td>\n",
       "      <td>108.50000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.239583</td>\n",
       "      <td>0.036440</td>\n",
       "      <td>0.062132</td>\n",
       "      <td>41.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.25</td>\n",
       "      <td>0.414226</td>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.471566</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.75</td>\n",
       "      <td>0.686282</td>\n",
       "      <td>0.287500</td>\n",
       "      <td>0.299025</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.50000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.381376</td>\n",
       "      <td>0.362647</td>\n",
       "      <td>0.370596</td>\n",
       "      <td>147.50000</td>\n",
       "      <td>0.677125</td>\n",
       "      <td>0.243013</td>\n",
       "      <td>0.220664</td>\n",
       "      <td>0.206619</td>\n",
       "      <td>1250.50000</td>\n",
       "      <td>0.655666</td>\n",
       "      <td>0.677125</td>\n",
       "      <td>0.657609</td>\n",
       "      <td>1250.50000</td>\n",
       "      <td>10.37955</td>\n",
       "      <td>121.859250</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.180794</td>\n",
       "      <td>0.008748</td>\n",
       "      <td>0.020756</td>\n",
       "      <td>0.008189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.038419</td>\n",
       "      <td>0.061868</td>\n",
       "      <td>0.032570</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.301184</td>\n",
       "      <td>0.058102</td>\n",
       "      <td>0.096925</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.045221</td>\n",
       "      <td>0.115869</td>\n",
       "      <td>0.049152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.365795</td>\n",
       "      <td>0.217466</td>\n",
       "      <td>0.141102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026449</td>\n",
       "      <td>0.023730</td>\n",
       "      <td>0.006604</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.013565</td>\n",
       "      <td>0.005524</td>\n",
       "      <td>0.025616</td>\n",
       "      <td>0.021365</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.011867</td>\n",
       "      <td>0.013565</td>\n",
       "      <td>0.010215</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>1.35503</td>\n",
       "      <td>14.120115</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def transform_to_regular_dict(result):\n",
    "    output_dict = {}\n",
    "    count = 0\n",
    "    for eval_item in result:\n",
    "        for key in eval_item:\n",
    "            if count == 0:\n",
    "              output_dict[key] = [float(eval_item[key])]\n",
    "            else:\n",
    "              output_dict[key].append(eval_item[key]) \n",
    "        count += 1\n",
    "    return output_dict\n",
    "            \n",
    "eval_dict = transform_to_regular_dict(result)\n",
    "eval_df = pd.DataFrame(eval_dict)\n",
    "\n",
    "def add_mean_std_row(df):\n",
    "    row_mean = []\n",
    "    row_std = []\n",
    "    for column in df:\n",
    "        row_mean.append(mean(df[column]))\n",
    "        row_std.append(stddev(df[column], ddof=1))\n",
    "    df = df.append(pd.DataFrame([row_mean], columns=df.columns), ignore_index=True)\n",
    "    df = df.append(pd.DataFrame([row_std], columns=df.columns), ignore_index=True)\n",
    "    # add better readable Index\n",
    "    df[\"fold\"] = [\"1\", \"2\", \"3\", \"4\", \"avg\", \"std\"]\n",
    "    df = df.set_index(\"fold\")\n",
    "    return df\n",
    "\n",
    "eval_df = add_mean_std_row(eval_df)\n",
    "display(HTML(eval_df.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ad0e60",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df57efb",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed76e5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for model in models:\n",
    "    model.save_model(f\"/data/experiments/raring/semantic_storytelling/data/model-ohnealles/{model_checkpoint.replace(r'/', '-')}/epoch_{num_epoch}/fold_{count}\")\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd633be",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff5f2271",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df.to_csv(f\"data/eval-ohnealles/{model_checkpoint.replace(r'/', '-')}_epoch_{num_epoch}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ef9e14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
