{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aquatic-australia",
   "metadata": {},
   "source": [
    "# Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8c9780a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model_checkpoint = 'bert-base-uncased'\n",
    "batch_size = 2\n",
    "metric_name = \"accuracy\"\n",
    "num_epoch = 10\n",
    "\n",
    "# Fold\n",
    "num_folds = 4\n",
    "\n",
    "# Experiment\n",
    "labels = [\"none\", \"causal\", \"contrast\", \"equivalence\", \"identity\", \"temporal\", \"others\"]\n",
    "def index_of_label(val):\n",
    "    global labels\n",
    "    try:\n",
    "        return labels.index(val)\n",
    "    except ValueError:\n",
    "        return len(labels_subset) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfcfcb1",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d51af5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8188a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_fold(path, fold):\n",
    "    train = pd.read_csv(f\"{path}/train.{fold}.csv\")\n",
    "    test = pd.read_csv(f\"{path}/test.{fold}.csv\")\n",
    "    train_origin = train[\"origin\"].tolist()\n",
    "    train_target = train[\"target\"].tolist()\n",
    "    train_labels = train[\"label\"].tolist()\n",
    "    test_origin = test[\"origin\"].tolist()\n",
    "    test_target = test[\"target\"].tolist()\n",
    "    test_labels = test[\"label\"].tolist()\n",
    "    return train_origin, train_target, train_labels, test_origin, test_target, test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1845b3",
   "metadata": {},
   "source": [
    "# Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a464f6",
   "metadata": {},
   "source": [
    "## Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "verbal-lexington",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import collections\n",
    "\n",
    "#classification_threshold = 0.\n",
    "\n",
    "def flatten(d, parent_key='', sep='__'):\n",
    "    items = []\n",
    "    for k, v in d.items():\n",
    "        new_key = parent_key + sep + k if parent_key else k\n",
    "        if isinstance(v, collections.MutableMapping):\n",
    "            items.extend(flatten(v, new_key, sep=sep).items())\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    global labels\n",
    "    predictions, true_labels = eval_pred\n",
    "    # take most probable guess\n",
    "    predictions = np.argmax(predictions, axis=-1)\n",
    "    return flatten(classification_report(\n",
    "        y_true=true_labels,\n",
    "        y_pred=predictions,\n",
    "        target_names=labels,\n",
    "        zero_division=0,\n",
    "        output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "opened-gambling",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST\n",
    "#flatten(classification_report(\n",
    "#    y_true=[0,1,2,3,4,5,6,7,8,9,10,11,12],\n",
    "#    y_pred=[0,0,0,1,3,0,0,0,0,0,0,0,0],\n",
    "#    target_names=labels,\n",
    "#    zero_division=0,\n",
    "#    output_dict=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attractive-taste",
   "metadata": {},
   "source": [
    "## Model Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "referenced-wichita",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "args = TrainingArguments(\n",
    "    \"semantic-test\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_epoch,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=metric_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accomplished-wedding",
   "metadata": {},
   "source": [
    "## Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sensitive-growth",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast, DebertaTokenizerFast\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_checkpoint)\n",
    "#tokenizer = DebertaTokenizerFast.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b7ee1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5cf32517",
   "metadata": {},
   "source": [
    "## Print Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efbd918e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#train_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbe4fd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_random_elements(origin_list, target_list, label_list, encodings, num_examples=10):\n",
    "    global labels\n",
    "    assert num_examples <= len(origin_list), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(origin_list)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(origin_list)-1)\n",
    "        picks.append(pick)\n",
    "    data = []\n",
    "    for n in picks:\n",
    "        data.append([n, origin_list[n], labels[label_list[n]], target_list[n], encodings.input_ids[n], encodings.token_type_ids[n], encodings.attention_mask[n]])\n",
    "    df = pd.DataFrame(data, columns=['index', 'Origin', 'Label', 'Target', 'Input_ids', 'Token_type_ids', 'Attention_mask'])\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cb93df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_random_elements(train_origin, train_target, train_labels, train_encodings)\n",
    "# Output adjustet to Folds\n",
    "#show_random_elements(k_fold_origin[0][0], k_fold_target[0][0], k_fold_labels[0][0], train_encodings[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prospective-lightweight",
   "metadata": {},
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "impressive-worth",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemanticDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fresh-destiny",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ultimate-winning",
   "metadata": {},
   "source": [
    "## Train & Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "environmental-medication",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18760' max='18760' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18760/18760 26:41, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>None  Precision</th>\n",
       "      <th>None  Recall</th>\n",
       "      <th>None  F1-score</th>\n",
       "      <th>None  Support</th>\n",
       "      <th>Causal  Precision</th>\n",
       "      <th>Causal  Recall</th>\n",
       "      <th>Causal  F1-score</th>\n",
       "      <th>Causal  Support</th>\n",
       "      <th>Contrast  Precision</th>\n",
       "      <th>Contrast  Recall</th>\n",
       "      <th>Contrast  F1-score</th>\n",
       "      <th>Contrast  Support</th>\n",
       "      <th>Equivalence  Precision</th>\n",
       "      <th>Equivalence  Recall</th>\n",
       "      <th>Equivalence  F1-score</th>\n",
       "      <th>Equivalence  Support</th>\n",
       "      <th>Identity  Precision</th>\n",
       "      <th>Identity  Recall</th>\n",
       "      <th>Identity  F1-score</th>\n",
       "      <th>Identity  Support</th>\n",
       "      <th>Temporal  Precision</th>\n",
       "      <th>Temporal  Recall</th>\n",
       "      <th>Temporal  F1-score</th>\n",
       "      <th>Temporal  Support</th>\n",
       "      <th>Others  Precision</th>\n",
       "      <th>Others  Recall</th>\n",
       "      <th>Others  F1-score</th>\n",
       "      <th>Others  Support</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro avg  Precision</th>\n",
       "      <th>Macro avg  Recall</th>\n",
       "      <th>Macro avg  F1-score</th>\n",
       "      <th>Macro avg  Support</th>\n",
       "      <th>Weighted avg  Precision</th>\n",
       "      <th>Weighted avg  Recall</th>\n",
       "      <th>Weighted avg  F1-score</th>\n",
       "      <th>Weighted avg  Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.145300</td>\n",
       "      <td>1.207678</td>\n",
       "      <td>0.761210</td>\n",
       "      <td>0.920555</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>793</td>\n",
       "      <td>0.200743</td>\n",
       "      <td>0.495413</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>0.044944</td>\n",
       "      <td>85</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.034014</td>\n",
       "      <td>0.060241</td>\n",
       "      <td>147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55</td>\n",
       "      <td>0.632294</td>\n",
       "      <td>0.246444</td>\n",
       "      <td>0.210502</td>\n",
       "      <td>0.174890</td>\n",
       "      <td>1251</td>\n",
       "      <td>0.564912</td>\n",
       "      <td>0.632294</td>\n",
       "      <td>0.563271</td>\n",
       "      <td>1251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.924100</td>\n",
       "      <td>1.215784</td>\n",
       "      <td>0.805869</td>\n",
       "      <td>0.900378</td>\n",
       "      <td>0.850506</td>\n",
       "      <td>793</td>\n",
       "      <td>0.329545</td>\n",
       "      <td>0.266055</td>\n",
       "      <td>0.294416</td>\n",
       "      <td>109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.321212</td>\n",
       "      <td>0.623529</td>\n",
       "      <td>0.424000</td>\n",
       "      <td>85</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.353741</td>\n",
       "      <td>0.401544</td>\n",
       "      <td>147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55</td>\n",
       "      <td>0.677858</td>\n",
       "      <td>0.274416</td>\n",
       "      <td>0.306243</td>\n",
       "      <td>0.281495</td>\n",
       "      <td>1251</td>\n",
       "      <td>0.615929</td>\n",
       "      <td>0.677858</td>\n",
       "      <td>0.640775</td>\n",
       "      <td>1251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.805700</td>\n",
       "      <td>1.203074</td>\n",
       "      <td>0.888418</td>\n",
       "      <td>0.793190</td>\n",
       "      <td>0.838108</td>\n",
       "      <td>793</td>\n",
       "      <td>0.401786</td>\n",
       "      <td>0.412844</td>\n",
       "      <td>0.407240</td>\n",
       "      <td>109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.378571</td>\n",
       "      <td>0.623529</td>\n",
       "      <td>0.471111</td>\n",
       "      <td>85</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>20</td>\n",
       "      <td>0.355805</td>\n",
       "      <td>0.646259</td>\n",
       "      <td>0.458937</td>\n",
       "      <td>147</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.131579</td>\n",
       "      <td>55</td>\n",
       "      <td>0.661871</td>\n",
       "      <td>0.394668</td>\n",
       "      <td>0.373819</td>\n",
       "      <td>0.342555</td>\n",
       "      <td>1251</td>\n",
       "      <td>0.684163</td>\n",
       "      <td>0.661871</td>\n",
       "      <td>0.659930</td>\n",
       "      <td>1251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.620500</td>\n",
       "      <td>1.479166</td>\n",
       "      <td>0.882759</td>\n",
       "      <td>0.807062</td>\n",
       "      <td>0.843215</td>\n",
       "      <td>793</td>\n",
       "      <td>0.389610</td>\n",
       "      <td>0.550459</td>\n",
       "      <td>0.456274</td>\n",
       "      <td>109</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>42</td>\n",
       "      <td>0.425532</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.530973</td>\n",
       "      <td>85</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>20</td>\n",
       "      <td>0.435294</td>\n",
       "      <td>0.503401</td>\n",
       "      <td>0.466877</td>\n",
       "      <td>147</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.109091</td>\n",
       "      <td>0.144578</td>\n",
       "      <td>55</td>\n",
       "      <td>0.681855</td>\n",
       "      <td>0.459504</td>\n",
       "      <td>0.452679</td>\n",
       "      <td>0.438556</td>\n",
       "      <td>1251</td>\n",
       "      <td>0.701923</td>\n",
       "      <td>0.681855</td>\n",
       "      <td>0.684947</td>\n",
       "      <td>1251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.430100</td>\n",
       "      <td>1.622784</td>\n",
       "      <td>0.845777</td>\n",
       "      <td>0.871375</td>\n",
       "      <td>0.858385</td>\n",
       "      <td>793</td>\n",
       "      <td>0.496000</td>\n",
       "      <td>0.568807</td>\n",
       "      <td>0.529915</td>\n",
       "      <td>109</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>42</td>\n",
       "      <td>0.643836</td>\n",
       "      <td>0.552941</td>\n",
       "      <td>0.594937</td>\n",
       "      <td>85</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>20</td>\n",
       "      <td>0.424051</td>\n",
       "      <td>0.455782</td>\n",
       "      <td>0.439344</td>\n",
       "      <td>147</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>55</td>\n",
       "      <td>0.718625</td>\n",
       "      <td>0.525397</td>\n",
       "      <td>0.491000</td>\n",
       "      <td>0.500583</td>\n",
       "      <td>1251</td>\n",
       "      <td>0.710169</td>\n",
       "      <td>0.718625</td>\n",
       "      <td>0.712040</td>\n",
       "      <td>1251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.288900</td>\n",
       "      <td>1.675451</td>\n",
       "      <td>0.872914</td>\n",
       "      <td>0.857503</td>\n",
       "      <td>0.865140</td>\n",
       "      <td>793</td>\n",
       "      <td>0.570093</td>\n",
       "      <td>0.559633</td>\n",
       "      <td>0.564815</td>\n",
       "      <td>109</td>\n",
       "      <td>0.339286</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.387755</td>\n",
       "      <td>42</td>\n",
       "      <td>0.765625</td>\n",
       "      <td>0.576471</td>\n",
       "      <td>0.657718</td>\n",
       "      <td>85</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>20</td>\n",
       "      <td>0.427632</td>\n",
       "      <td>0.442177</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>147</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.327273</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>55</td>\n",
       "      <td>0.722622</td>\n",
       "      <td>0.533774</td>\n",
       "      <td>0.545062</td>\n",
       "      <td>0.535141</td>\n",
       "      <td>1251</td>\n",
       "      <td>0.736130</td>\n",
       "      <td>0.722622</td>\n",
       "      <td>0.727900</td>\n",
       "      <td>1251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.233100</td>\n",
       "      <td>1.874238</td>\n",
       "      <td>0.846626</td>\n",
       "      <td>0.870113</td>\n",
       "      <td>0.858209</td>\n",
       "      <td>793</td>\n",
       "      <td>0.635417</td>\n",
       "      <td>0.559633</td>\n",
       "      <td>0.595122</td>\n",
       "      <td>109</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>42</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.576471</td>\n",
       "      <td>0.662162</td>\n",
       "      <td>85</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.595745</td>\n",
       "      <td>20</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.442177</td>\n",
       "      <td>0.445205</td>\n",
       "      <td>147</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>55</td>\n",
       "      <td>0.733813</td>\n",
       "      <td>0.589516</td>\n",
       "      <td>0.566344</td>\n",
       "      <td>0.570273</td>\n",
       "      <td>1251</td>\n",
       "      <td>0.738832</td>\n",
       "      <td>0.733813</td>\n",
       "      <td>0.733942</td>\n",
       "      <td>1251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.102300</td>\n",
       "      <td>1.987502</td>\n",
       "      <td>0.873533</td>\n",
       "      <td>0.844893</td>\n",
       "      <td>0.858974</td>\n",
       "      <td>793</td>\n",
       "      <td>0.565891</td>\n",
       "      <td>0.669725</td>\n",
       "      <td>0.613445</td>\n",
       "      <td>109</td>\n",
       "      <td>0.659091</td>\n",
       "      <td>0.690476</td>\n",
       "      <td>0.674419</td>\n",
       "      <td>42</td>\n",
       "      <td>0.691358</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>0.674699</td>\n",
       "      <td>85</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>20</td>\n",
       "      <td>0.422819</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.425676</td>\n",
       "      <td>147</td>\n",
       "      <td>0.387097</td>\n",
       "      <td>0.436364</td>\n",
       "      <td>0.410256</td>\n",
       "      <td>55</td>\n",
       "      <td>0.741807</td>\n",
       "      <td>0.612000</td>\n",
       "      <td>0.625550</td>\n",
       "      <td>0.617734</td>\n",
       "      <td>1251</td>\n",
       "      <td>0.749776</td>\n",
       "      <td>0.741807</td>\n",
       "      <td>0.745147</td>\n",
       "      <td>1251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.021500</td>\n",
       "      <td>2.066607</td>\n",
       "      <td>0.865311</td>\n",
       "      <td>0.858764</td>\n",
       "      <td>0.862025</td>\n",
       "      <td>793</td>\n",
       "      <td>0.544776</td>\n",
       "      <td>0.669725</td>\n",
       "      <td>0.600823</td>\n",
       "      <td>109</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.753425</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.696203</td>\n",
       "      <td>85</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>20</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.425856</td>\n",
       "      <td>147</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.336134</td>\n",
       "      <td>55</td>\n",
       "      <td>0.741807</td>\n",
       "      <td>0.594318</td>\n",
       "      <td>0.612060</td>\n",
       "      <td>0.598244</td>\n",
       "      <td>1251</td>\n",
       "      <td>0.745943</td>\n",
       "      <td>0.741807</td>\n",
       "      <td>0.741706</td>\n",
       "      <td>1251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>2.080004</td>\n",
       "      <td>0.874674</td>\n",
       "      <td>0.844893</td>\n",
       "      <td>0.859525</td>\n",
       "      <td>793</td>\n",
       "      <td>0.541985</td>\n",
       "      <td>0.651376</td>\n",
       "      <td>0.591667</td>\n",
       "      <td>109</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.690476</td>\n",
       "      <td>0.651685</td>\n",
       "      <td>42</td>\n",
       "      <td>0.726027</td>\n",
       "      <td>0.623529</td>\n",
       "      <td>0.670886</td>\n",
       "      <td>85</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.717949</td>\n",
       "      <td>20</td>\n",
       "      <td>0.456376</td>\n",
       "      <td>0.462585</td>\n",
       "      <td>0.459459</td>\n",
       "      <td>147</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>55</td>\n",
       "      <td>0.741007</td>\n",
       "      <td>0.612323</td>\n",
       "      <td>0.624694</td>\n",
       "      <td>0.616401</td>\n",
       "      <td>1251</td>\n",
       "      <td>0.751780</td>\n",
       "      <td>0.741007</td>\n",
       "      <td>0.745316</td>\n",
       "      <td>1251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-c906eaaad80e>:10: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n",
      "  if isinstance(v, collections.MutableMapping):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='626' max='626' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [626/626 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7418065547561951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18760' max='18760' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18760/18760 26:47, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>None  Precision</th>\n",
       "      <th>None  Recall</th>\n",
       "      <th>None  F1-score</th>\n",
       "      <th>None  Support</th>\n",
       "      <th>Causal  Precision</th>\n",
       "      <th>Causal  Recall</th>\n",
       "      <th>Causal  F1-score</th>\n",
       "      <th>Causal  Support</th>\n",
       "      <th>Contrast  Precision</th>\n",
       "      <th>Contrast  Recall</th>\n",
       "      <th>Contrast  F1-score</th>\n",
       "      <th>Contrast  Support</th>\n",
       "      <th>Equivalence  Precision</th>\n",
       "      <th>Equivalence  Recall</th>\n",
       "      <th>Equivalence  F1-score</th>\n",
       "      <th>Equivalence  Support</th>\n",
       "      <th>Identity  Precision</th>\n",
       "      <th>Identity  Recall</th>\n",
       "      <th>Identity  F1-score</th>\n",
       "      <th>Identity  Support</th>\n",
       "      <th>Temporal  Precision</th>\n",
       "      <th>Temporal  Recall</th>\n",
       "      <th>Temporal  F1-score</th>\n",
       "      <th>Temporal  Support</th>\n",
       "      <th>Others  Precision</th>\n",
       "      <th>Others  Recall</th>\n",
       "      <th>Others  F1-score</th>\n",
       "      <th>Others  Support</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro avg  Precision</th>\n",
       "      <th>Macro avg  Recall</th>\n",
       "      <th>Macro avg  F1-score</th>\n",
       "      <th>Macro avg  Support</th>\n",
       "      <th>Weighted avg  Precision</th>\n",
       "      <th>Weighted avg  Recall</th>\n",
       "      <th>Weighted avg  F1-score</th>\n",
       "      <th>Weighted avg  Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.194100</td>\n",
       "      <td>1.175283</td>\n",
       "      <td>0.771310</td>\n",
       "      <td>0.935687</td>\n",
       "      <td>0.845584</td>\n",
       "      <td>793</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41</td>\n",
       "      <td>0.242215</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.374332</td>\n",
       "      <td>85</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56</td>\n",
       "      <td>0.649081</td>\n",
       "      <td>0.144789</td>\n",
       "      <td>0.251317</td>\n",
       "      <td>0.174274</td>\n",
       "      <td>1251</td>\n",
       "      <td>0.505385</td>\n",
       "      <td>0.649081</td>\n",
       "      <td>0.561444</td>\n",
       "      <td>1251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.923000</td>\n",
       "      <td>0.933314</td>\n",
       "      <td>0.869509</td>\n",
       "      <td>0.848676</td>\n",
       "      <td>0.858966</td>\n",
       "      <td>793</td>\n",
       "      <td>0.419355</td>\n",
       "      <td>0.238532</td>\n",
       "      <td>0.304094</td>\n",
       "      <td>109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41</td>\n",
       "      <td>0.268398</td>\n",
       "      <td>0.729412</td>\n",
       "      <td>0.392405</td>\n",
       "      <td>85</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20</td>\n",
       "      <td>0.489130</td>\n",
       "      <td>0.612245</td>\n",
       "      <td>0.543807</td>\n",
       "      <td>147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56</td>\n",
       "      <td>0.680256</td>\n",
       "      <td>0.292342</td>\n",
       "      <td>0.346981</td>\n",
       "      <td>0.299896</td>\n",
       "      <td>1251</td>\n",
       "      <td>0.663426</td>\n",
       "      <td>0.680256</td>\n",
       "      <td>0.661551</td>\n",
       "      <td>1251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.788000</td>\n",
       "      <td>1.057299</td>\n",
       "      <td>0.897606</td>\n",
       "      <td>0.851198</td>\n",
       "      <td>0.873786</td>\n",
       "      <td>793</td>\n",
       "      <td>0.406015</td>\n",
       "      <td>0.495413</td>\n",
       "      <td>0.446281</td>\n",
       "      <td>109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41</td>\n",
       "      <td>0.393939</td>\n",
       "      <td>0.611765</td>\n",
       "      <td>0.479263</td>\n",
       "      <td>85</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20</td>\n",
       "      <td>0.439252</td>\n",
       "      <td>0.639456</td>\n",
       "      <td>0.520776</td>\n",
       "      <td>147</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.089286</td>\n",
       "      <td>0.131579</td>\n",
       "      <td>56</td>\n",
       "      <td>0.703437</td>\n",
       "      <td>0.340973</td>\n",
       "      <td>0.383874</td>\n",
       "      <td>0.350241</td>\n",
       "      <td>1251</td>\n",
       "      <td>0.693935</td>\n",
       "      <td>0.703437</td>\n",
       "      <td>0.692420</td>\n",
       "      <td>1251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.682400</td>\n",
       "      <td>1.381366</td>\n",
       "      <td>0.885604</td>\n",
       "      <td>0.868852</td>\n",
       "      <td>0.877148</td>\n",
       "      <td>793</td>\n",
       "      <td>0.423611</td>\n",
       "      <td>0.559633</td>\n",
       "      <td>0.482213</td>\n",
       "      <td>109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41</td>\n",
       "      <td>0.519608</td>\n",
       "      <td>0.623529</td>\n",
       "      <td>0.566845</td>\n",
       "      <td>85</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>20</td>\n",
       "      <td>0.398990</td>\n",
       "      <td>0.537415</td>\n",
       "      <td>0.457971</td>\n",
       "      <td>147</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.168675</td>\n",
       "      <td>56</td>\n",
       "      <td>0.712230</td>\n",
       "      <td>0.498153</td>\n",
       "      <td>0.402061</td>\n",
       "      <td>0.390667</td>\n",
       "      <td>1251</td>\n",
       "      <td>0.708069</td>\n",
       "      <td>0.712230</td>\n",
       "      <td>0.700820</td>\n",
       "      <td>1251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.456300</td>\n",
       "      <td>1.483635</td>\n",
       "      <td>0.867485</td>\n",
       "      <td>0.891551</td>\n",
       "      <td>0.879353</td>\n",
       "      <td>793</td>\n",
       "      <td>0.452229</td>\n",
       "      <td>0.651376</td>\n",
       "      <td>0.533835</td>\n",
       "      <td>109</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>41</td>\n",
       "      <td>0.590476</td>\n",
       "      <td>0.729412</td>\n",
       "      <td>0.652632</td>\n",
       "      <td>85</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>20</td>\n",
       "      <td>0.503937</td>\n",
       "      <td>0.435374</td>\n",
       "      <td>0.467153</td>\n",
       "      <td>147</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.170213</td>\n",
       "      <td>56</td>\n",
       "      <td>0.732214</td>\n",
       "      <td>0.507604</td>\n",
       "      <td>0.432137</td>\n",
       "      <td>0.424560</td>\n",
       "      <td>1251</td>\n",
       "      <td>0.721294</td>\n",
       "      <td>0.732214</td>\n",
       "      <td>0.715862</td>\n",
       "      <td>1251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.236900</td>\n",
       "      <td>1.656163</td>\n",
       "      <td>0.869193</td>\n",
       "      <td>0.896595</td>\n",
       "      <td>0.882682</td>\n",
       "      <td>793</td>\n",
       "      <td>0.514493</td>\n",
       "      <td>0.651376</td>\n",
       "      <td>0.574899</td>\n",
       "      <td>109</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.146341</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>41</td>\n",
       "      <td>0.662338</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>85</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>20</td>\n",
       "      <td>0.513158</td>\n",
       "      <td>0.530612</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>147</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.267857</td>\n",
       "      <td>0.297030</td>\n",
       "      <td>56</td>\n",
       "      <td>0.750600</td>\n",
       "      <td>0.591138</td>\n",
       "      <td>0.491826</td>\n",
       "      <td>0.514774</td>\n",
       "      <td>1251</td>\n",
       "      <td>0.745094</td>\n",
       "      <td>0.750600</td>\n",
       "      <td>0.742025</td>\n",
       "      <td>1251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.111400</td>\n",
       "      <td>1.775691</td>\n",
       "      <td>0.881910</td>\n",
       "      <td>0.885246</td>\n",
       "      <td>0.883575</td>\n",
       "      <td>793</td>\n",
       "      <td>0.440678</td>\n",
       "      <td>0.715596</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>109</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.341463</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>41</td>\n",
       "      <td>0.679012</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.662651</td>\n",
       "      <td>85</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>20</td>\n",
       "      <td>0.515625</td>\n",
       "      <td>0.448980</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>147</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.232143</td>\n",
       "      <td>0.313253</td>\n",
       "      <td>56</td>\n",
       "      <td>0.750600</td>\n",
       "      <td>0.618231</td>\n",
       "      <td>0.545784</td>\n",
       "      <td>0.564514</td>\n",
       "      <td>1251</td>\n",
       "      <td>0.755060</td>\n",
       "      <td>0.750600</td>\n",
       "      <td>0.746835</td>\n",
       "      <td>1251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.081000</td>\n",
       "      <td>1.874965</td>\n",
       "      <td>0.893561</td>\n",
       "      <td>0.857503</td>\n",
       "      <td>0.875161</td>\n",
       "      <td>793</td>\n",
       "      <td>0.437186</td>\n",
       "      <td>0.798165</td>\n",
       "      <td>0.564935</td>\n",
       "      <td>109</td>\n",
       "      <td>0.435897</td>\n",
       "      <td>0.414634</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>41</td>\n",
       "      <td>0.776119</td>\n",
       "      <td>0.611765</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>85</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>20</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.489796</td>\n",
       "      <td>0.505263</td>\n",
       "      <td>147</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.267857</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>56</td>\n",
       "      <td>0.748201</td>\n",
       "      <td>0.628560</td>\n",
       "      <td>0.584246</td>\n",
       "      <td>0.591191</td>\n",
       "      <td>1251</td>\n",
       "      <td>0.767680</td>\n",
       "      <td>0.748201</td>\n",
       "      <td>0.750907</td>\n",
       "      <td>1251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.021800</td>\n",
       "      <td>1.861705</td>\n",
       "      <td>0.860409</td>\n",
       "      <td>0.901639</td>\n",
       "      <td>0.880542</td>\n",
       "      <td>793</td>\n",
       "      <td>0.603448</td>\n",
       "      <td>0.642202</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>109</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>0.530120</td>\n",
       "      <td>41</td>\n",
       "      <td>0.786667</td>\n",
       "      <td>0.694118</td>\n",
       "      <td>0.737500</td>\n",
       "      <td>85</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>20</td>\n",
       "      <td>0.515873</td>\n",
       "      <td>0.442177</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>147</td>\n",
       "      <td>0.456522</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>56</td>\n",
       "      <td>0.770584</td>\n",
       "      <td>0.649533</td>\n",
       "      <td>0.598817</td>\n",
       "      <td>0.620579</td>\n",
       "      <td>1251</td>\n",
       "      <td>0.762447</td>\n",
       "      <td>0.770584</td>\n",
       "      <td>0.765218</td>\n",
       "      <td>1251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.018500</td>\n",
       "      <td>1.916510</td>\n",
       "      <td>0.870807</td>\n",
       "      <td>0.883985</td>\n",
       "      <td>0.877347</td>\n",
       "      <td>793</td>\n",
       "      <td>0.561538</td>\n",
       "      <td>0.669725</td>\n",
       "      <td>0.610879</td>\n",
       "      <td>109</td>\n",
       "      <td>0.462963</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>41</td>\n",
       "      <td>0.794521</td>\n",
       "      <td>0.682353</td>\n",
       "      <td>0.734177</td>\n",
       "      <td>85</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>20</td>\n",
       "      <td>0.485507</td>\n",
       "      <td>0.455782</td>\n",
       "      <td>0.470175</td>\n",
       "      <td>147</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>56</td>\n",
       "      <td>0.764988</td>\n",
       "      <td>0.656794</td>\n",
       "      <td>0.615535</td>\n",
       "      <td>0.628076</td>\n",
       "      <td>1251</td>\n",
       "      <td>0.765858</td>\n",
       "      <td>0.764988</td>\n",
       "      <td>0.763091</td>\n",
       "      <td>1251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='626' max='626' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [626/626 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7705835331734612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18760' max='18760' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18760/18760 25:36, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>None  Precision</th>\n",
       "      <th>None  Recall</th>\n",
       "      <th>None  F1-score</th>\n",
       "      <th>None  Support</th>\n",
       "      <th>Causal  Precision</th>\n",
       "      <th>Causal  Recall</th>\n",
       "      <th>Causal  F1-score</th>\n",
       "      <th>Causal  Support</th>\n",
       "      <th>Contrast  Precision</th>\n",
       "      <th>Contrast  Recall</th>\n",
       "      <th>Contrast  F1-score</th>\n",
       "      <th>Contrast  Support</th>\n",
       "      <th>Equivalence  Precision</th>\n",
       "      <th>Equivalence  Recall</th>\n",
       "      <th>Equivalence  F1-score</th>\n",
       "      <th>Equivalence  Support</th>\n",
       "      <th>Identity  Precision</th>\n",
       "      <th>Identity  Recall</th>\n",
       "      <th>Identity  F1-score</th>\n",
       "      <th>Identity  Support</th>\n",
       "      <th>Temporal  Precision</th>\n",
       "      <th>Temporal  Recall</th>\n",
       "      <th>Temporal  F1-score</th>\n",
       "      <th>Temporal  Support</th>\n",
       "      <th>Others  Precision</th>\n",
       "      <th>Others  Recall</th>\n",
       "      <th>Others  F1-score</th>\n",
       "      <th>Others  Support</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro avg  Precision</th>\n",
       "      <th>Macro avg  Recall</th>\n",
       "      <th>Macro avg  F1-score</th>\n",
       "      <th>Macro avg  Support</th>\n",
       "      <th>Weighted avg  Precision</th>\n",
       "      <th>Weighted avg  Recall</th>\n",
       "      <th>Weighted avg  F1-score</th>\n",
       "      <th>Weighted avg  Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.147300</td>\n",
       "      <td>1.092206</td>\n",
       "      <td>0.765756</td>\n",
       "      <td>0.919294</td>\n",
       "      <td>0.835530</td>\n",
       "      <td>793</td>\n",
       "      <td>0.241667</td>\n",
       "      <td>0.268519</td>\n",
       "      <td>0.254386</td>\n",
       "      <td>108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41</td>\n",
       "      <td>0.338983</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.394089</td>\n",
       "      <td>85</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.121622</td>\n",
       "      <td>0.173077</td>\n",
       "      <td>148</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55</td>\n",
       "      <td>0.652800</td>\n",
       "      <td>0.235201</td>\n",
       "      <td>0.254289</td>\n",
       "      <td>0.236726</td>\n",
       "      <td>1250</td>\n",
       "      <td>0.565247</td>\n",
       "      <td>0.652800</td>\n",
       "      <td>0.599330</td>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.958600</td>\n",
       "      <td>1.343463</td>\n",
       "      <td>0.788889</td>\n",
       "      <td>0.895334</td>\n",
       "      <td>0.838748</td>\n",
       "      <td>793</td>\n",
       "      <td>0.224719</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.203046</td>\n",
       "      <td>108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41</td>\n",
       "      <td>0.317365</td>\n",
       "      <td>0.623529</td>\n",
       "      <td>0.420635</td>\n",
       "      <td>85</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20</td>\n",
       "      <td>0.340426</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>0.264463</td>\n",
       "      <td>148</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55</td>\n",
       "      <td>0.652000</td>\n",
       "      <td>0.238771</td>\n",
       "      <td>0.274324</td>\n",
       "      <td>0.246699</td>\n",
       "      <td>1250</td>\n",
       "      <td>0.581774</td>\n",
       "      <td>0.652000</td>\n",
       "      <td>0.609560</td>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.751300</td>\n",
       "      <td>1.227510</td>\n",
       "      <td>0.837349</td>\n",
       "      <td>0.876419</td>\n",
       "      <td>0.856439</td>\n",
       "      <td>793</td>\n",
       "      <td>0.321918</td>\n",
       "      <td>0.435185</td>\n",
       "      <td>0.370079</td>\n",
       "      <td>108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.576471</td>\n",
       "      <td>0.464455</td>\n",
       "      <td>85</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>20</td>\n",
       "      <td>0.433628</td>\n",
       "      <td>0.331081</td>\n",
       "      <td>0.375479</td>\n",
       "      <td>148</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.145455</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>55</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.370140</td>\n",
       "      <td>0.352087</td>\n",
       "      <td>0.344396</td>\n",
       "      <td>1250</td>\n",
       "      <td>0.654285</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.662182</td>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.607200</td>\n",
       "      <td>1.511092</td>\n",
       "      <td>0.858667</td>\n",
       "      <td>0.812106</td>\n",
       "      <td>0.834738</td>\n",
       "      <td>793</td>\n",
       "      <td>0.385714</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.435484</td>\n",
       "      <td>108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.614458</td>\n",
       "      <td>85</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>20</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.520270</td>\n",
       "      <td>0.431373</td>\n",
       "      <td>148</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.327273</td>\n",
       "      <td>0.292683</td>\n",
       "      <td>55</td>\n",
       "      <td>0.676800</td>\n",
       "      <td>0.501020</td>\n",
       "      <td>0.408521</td>\n",
       "      <td>0.398650</td>\n",
       "      <td>1250</td>\n",
       "      <td>0.692147</td>\n",
       "      <td>0.676800</td>\n",
       "      <td>0.675828</td>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.474100</td>\n",
       "      <td>1.856478</td>\n",
       "      <td>0.856404</td>\n",
       "      <td>0.834805</td>\n",
       "      <td>0.845466</td>\n",
       "      <td>793</td>\n",
       "      <td>0.357488</td>\n",
       "      <td>0.685185</td>\n",
       "      <td>0.469841</td>\n",
       "      <td>108</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>41</td>\n",
       "      <td>0.686567</td>\n",
       "      <td>0.541176</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>85</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>20</td>\n",
       "      <td>0.376712</td>\n",
       "      <td>0.371622</td>\n",
       "      <td>0.374150</td>\n",
       "      <td>148</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.218182</td>\n",
       "      <td>0.237624</td>\n",
       "      <td>55</td>\n",
       "      <td>0.685600</td>\n",
       "      <td>0.605434</td>\n",
       "      <td>0.432194</td>\n",
       "      <td>0.435233</td>\n",
       "      <td>1250</td>\n",
       "      <td>0.720957</td>\n",
       "      <td>0.685600</td>\n",
       "      <td>0.681899</td>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.239900</td>\n",
       "      <td>2.021365</td>\n",
       "      <td>0.842040</td>\n",
       "      <td>0.853720</td>\n",
       "      <td>0.847840</td>\n",
       "      <td>793</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.601852</td>\n",
       "      <td>0.513834</td>\n",
       "      <td>108</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.219512</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>41</td>\n",
       "      <td>0.753425</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.696203</td>\n",
       "      <td>85</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>20</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.391892</td>\n",
       "      <td>0.395904</td>\n",
       "      <td>148</td>\n",
       "      <td>0.280702</td>\n",
       "      <td>0.290909</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>55</td>\n",
       "      <td>0.711200</td>\n",
       "      <td>0.591803</td>\n",
       "      <td>0.493563</td>\n",
       "      <td>0.520224</td>\n",
       "      <td>1250</td>\n",
       "      <td>0.716636</td>\n",
       "      <td>0.711200</td>\n",
       "      <td>0.708886</td>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.131700</td>\n",
       "      <td>2.159104</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.862547</td>\n",
       "      <td>0.849689</td>\n",
       "      <td>793</td>\n",
       "      <td>0.507937</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.547009</td>\n",
       "      <td>108</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.365854</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>41</td>\n",
       "      <td>0.761194</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.671053</td>\n",
       "      <td>85</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>20</td>\n",
       "      <td>0.360544</td>\n",
       "      <td>0.358108</td>\n",
       "      <td>0.359322</td>\n",
       "      <td>148</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.254545</td>\n",
       "      <td>0.264151</td>\n",
       "      <td>55</td>\n",
       "      <td>0.713600</td>\n",
       "      <td>0.580403</td>\n",
       "      <td>0.511950</td>\n",
       "      <td>0.539009</td>\n",
       "      <td>1250</td>\n",
       "      <td>0.711682</td>\n",
       "      <td>0.713600</td>\n",
       "      <td>0.710716</td>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.043800</td>\n",
       "      <td>2.191030</td>\n",
       "      <td>0.850126</td>\n",
       "      <td>0.851198</td>\n",
       "      <td>0.850662</td>\n",
       "      <td>793</td>\n",
       "      <td>0.551181</td>\n",
       "      <td>0.648148</td>\n",
       "      <td>0.595745</td>\n",
       "      <td>108</td>\n",
       "      <td>0.489796</td>\n",
       "      <td>0.585366</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>41</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.635294</td>\n",
       "      <td>0.696774</td>\n",
       "      <td>85</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>20</td>\n",
       "      <td>0.386207</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.382253</td>\n",
       "      <td>148</td>\n",
       "      <td>0.283019</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>55</td>\n",
       "      <td>0.723200</td>\n",
       "      <td>0.595013</td>\n",
       "      <td>0.553016</td>\n",
       "      <td>0.565935</td>\n",
       "      <td>1250</td>\n",
       "      <td>0.726977</td>\n",
       "      <td>0.723200</td>\n",
       "      <td>0.723487</td>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.041400</td>\n",
       "      <td>2.370014</td>\n",
       "      <td>0.853846</td>\n",
       "      <td>0.839849</td>\n",
       "      <td>0.846790</td>\n",
       "      <td>793</td>\n",
       "      <td>0.543307</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.587234</td>\n",
       "      <td>108</td>\n",
       "      <td>0.489362</td>\n",
       "      <td>0.560976</td>\n",
       "      <td>0.522727</td>\n",
       "      <td>41</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.635294</td>\n",
       "      <td>0.701299</td>\n",
       "      <td>85</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>20</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>0.351351</td>\n",
       "      <td>0.356164</td>\n",
       "      <td>148</td>\n",
       "      <td>0.283582</td>\n",
       "      <td>0.345455</td>\n",
       "      <td>0.311475</td>\n",
       "      <td>55</td>\n",
       "      <td>0.717600</td>\n",
       "      <td>0.598402</td>\n",
       "      <td>0.581688</td>\n",
       "      <td>0.586210</td>\n",
       "      <td>1250</td>\n",
       "      <td>0.727123</td>\n",
       "      <td>0.717600</td>\n",
       "      <td>0.721093</td>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>2.400868</td>\n",
       "      <td>0.845570</td>\n",
       "      <td>0.842371</td>\n",
       "      <td>0.843967</td>\n",
       "      <td>793</td>\n",
       "      <td>0.514925</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.570248</td>\n",
       "      <td>108</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.634146</td>\n",
       "      <td>0.559140</td>\n",
       "      <td>41</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.689189</td>\n",
       "      <td>85</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>20</td>\n",
       "      <td>0.368056</td>\n",
       "      <td>0.358108</td>\n",
       "      <td>0.363014</td>\n",
       "      <td>148</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.290909</td>\n",
       "      <td>0.299065</td>\n",
       "      <td>55</td>\n",
       "      <td>0.716800</td>\n",
       "      <td>0.601776</td>\n",
       "      <td>0.573489</td>\n",
       "      <td>0.581069</td>\n",
       "      <td>1250</td>\n",
       "      <td>0.723349</td>\n",
       "      <td>0.716800</td>\n",
       "      <td>0.717912</td>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18760' max='18760' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18760/18760 22:20, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>None  Precision</th>\n",
       "      <th>None  Recall</th>\n",
       "      <th>None  F1-score</th>\n",
       "      <th>None  Support</th>\n",
       "      <th>Causal  Precision</th>\n",
       "      <th>Causal  Recall</th>\n",
       "      <th>Causal  F1-score</th>\n",
       "      <th>Causal  Support</th>\n",
       "      <th>Contrast  Precision</th>\n",
       "      <th>Contrast  Recall</th>\n",
       "      <th>Contrast  F1-score</th>\n",
       "      <th>Contrast  Support</th>\n",
       "      <th>Equivalence  Precision</th>\n",
       "      <th>Equivalence  Recall</th>\n",
       "      <th>Equivalence  F1-score</th>\n",
       "      <th>Equivalence  Support</th>\n",
       "      <th>Identity  Precision</th>\n",
       "      <th>Identity  Recall</th>\n",
       "      <th>Identity  F1-score</th>\n",
       "      <th>Identity  Support</th>\n",
       "      <th>Temporal  Precision</th>\n",
       "      <th>Temporal  Recall</th>\n",
       "      <th>Temporal  F1-score</th>\n",
       "      <th>Temporal  Support</th>\n",
       "      <th>Others  Precision</th>\n",
       "      <th>Others  Recall</th>\n",
       "      <th>Others  F1-score</th>\n",
       "      <th>Others  Support</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro avg  Precision</th>\n",
       "      <th>Macro avg  Recall</th>\n",
       "      <th>Macro avg  F1-score</th>\n",
       "      <th>Macro avg  Support</th>\n",
       "      <th>Weighted avg  Precision</th>\n",
       "      <th>Weighted avg  Recall</th>\n",
       "      <th>Weighted avg  F1-score</th>\n",
       "      <th>Weighted avg  Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.128200</td>\n",
       "      <td>1.089031</td>\n",
       "      <td>0.770314</td>\n",
       "      <td>0.896595</td>\n",
       "      <td>0.828671</td>\n",
       "      <td>793</td>\n",
       "      <td>0.191126</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.279302</td>\n",
       "      <td>108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>85</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.114865</td>\n",
       "      <td>0.186813</td>\n",
       "      <td>148</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55</td>\n",
       "      <td>0.627200</td>\n",
       "      <td>0.208777</td>\n",
       "      <td>0.218568</td>\n",
       "      <td>0.184969</td>\n",
       "      <td>1250</td>\n",
       "      <td>0.564401</td>\n",
       "      <td>0.627200</td>\n",
       "      <td>0.571959</td>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.002900</td>\n",
       "      <td>1.085252</td>\n",
       "      <td>0.884097</td>\n",
       "      <td>0.827238</td>\n",
       "      <td>0.854723</td>\n",
       "      <td>793</td>\n",
       "      <td>0.341270</td>\n",
       "      <td>0.398148</td>\n",
       "      <td>0.367521</td>\n",
       "      <td>108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41</td>\n",
       "      <td>0.254054</td>\n",
       "      <td>0.552941</td>\n",
       "      <td>0.348148</td>\n",
       "      <td>85</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20</td>\n",
       "      <td>0.436548</td>\n",
       "      <td>0.581081</td>\n",
       "      <td>0.498551</td>\n",
       "      <td>148</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55</td>\n",
       "      <td>0.665600</td>\n",
       "      <td>0.273710</td>\n",
       "      <td>0.337058</td>\n",
       "      <td>0.295563</td>\n",
       "      <td>1250</td>\n",
       "      <td>0.659320</td>\n",
       "      <td>0.665600</td>\n",
       "      <td>0.656693</td>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.704900</td>\n",
       "      <td>1.341398</td>\n",
       "      <td>0.809795</td>\n",
       "      <td>0.896595</td>\n",
       "      <td>0.850987</td>\n",
       "      <td>793</td>\n",
       "      <td>0.351351</td>\n",
       "      <td>0.240741</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41</td>\n",
       "      <td>0.358491</td>\n",
       "      <td>0.447059</td>\n",
       "      <td>0.397906</td>\n",
       "      <td>85</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20</td>\n",
       "      <td>0.370166</td>\n",
       "      <td>0.452703</td>\n",
       "      <td>0.407295</td>\n",
       "      <td>148</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>0.061538</td>\n",
       "      <td>55</td>\n",
       "      <td>0.675200</td>\n",
       "      <td>0.298543</td>\n",
       "      <td>0.296209</td>\n",
       "      <td>0.286206</td>\n",
       "      <td>1250</td>\n",
       "      <td>0.621096</td>\n",
       "      <td>0.675200</td>\n",
       "      <td>0.642541</td>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.621600</td>\n",
       "      <td>1.542172</td>\n",
       "      <td>0.833537</td>\n",
       "      <td>0.858764</td>\n",
       "      <td>0.845963</td>\n",
       "      <td>793</td>\n",
       "      <td>0.416107</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.482490</td>\n",
       "      <td>108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.494118</td>\n",
       "      <td>0.435233</td>\n",
       "      <td>85</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20</td>\n",
       "      <td>0.419580</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.412371</td>\n",
       "      <td>148</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.236364</td>\n",
       "      <td>0.305882</td>\n",
       "      <td>55</td>\n",
       "      <td>0.686400</td>\n",
       "      <td>0.355921</td>\n",
       "      <td>0.366961</td>\n",
       "      <td>0.354563</td>\n",
       "      <td>1250</td>\n",
       "      <td>0.659937</td>\n",
       "      <td>0.686400</td>\n",
       "      <td>0.670245</td>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.377000</td>\n",
       "      <td>1.911284</td>\n",
       "      <td>0.825208</td>\n",
       "      <td>0.875158</td>\n",
       "      <td>0.849449</td>\n",
       "      <td>793</td>\n",
       "      <td>0.403361</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.422907</td>\n",
       "      <td>108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.258824</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>85</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>20</td>\n",
       "      <td>0.343434</td>\n",
       "      <td>0.459459</td>\n",
       "      <td>0.393064</td>\n",
       "      <td>148</td>\n",
       "      <td>0.234043</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.215686</td>\n",
       "      <td>55</td>\n",
       "      <td>0.680800</td>\n",
       "      <td>0.448014</td>\n",
       "      <td>0.376841</td>\n",
       "      <td>0.391094</td>\n",
       "      <td>1250</td>\n",
       "      <td>0.670052</td>\n",
       "      <td>0.680800</td>\n",
       "      <td>0.665234</td>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.221600</td>\n",
       "      <td>1.860110</td>\n",
       "      <td>0.837740</td>\n",
       "      <td>0.878941</td>\n",
       "      <td>0.857846</td>\n",
       "      <td>793</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>108</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.292683</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>41</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.317647</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>85</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>20</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.432432</td>\n",
       "      <td>0.426667</td>\n",
       "      <td>148</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.327273</td>\n",
       "      <td>0.349515</td>\n",
       "      <td>55</td>\n",
       "      <td>0.716800</td>\n",
       "      <td>0.573991</td>\n",
       "      <td>0.494298</td>\n",
       "      <td>0.516727</td>\n",
       "      <td>1250</td>\n",
       "      <td>0.716945</td>\n",
       "      <td>0.716800</td>\n",
       "      <td>0.708862</td>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.089200</td>\n",
       "      <td>2.003365</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.862547</td>\n",
       "      <td>0.858218</td>\n",
       "      <td>793</td>\n",
       "      <td>0.440252</td>\n",
       "      <td>0.648148</td>\n",
       "      <td>0.524345</td>\n",
       "      <td>108</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.292683</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>41</td>\n",
       "      <td>0.672414</td>\n",
       "      <td>0.458824</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>85</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>20</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.425676</td>\n",
       "      <td>0.448399</td>\n",
       "      <td>148</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.327273</td>\n",
       "      <td>0.330275</td>\n",
       "      <td>55</td>\n",
       "      <td>0.717600</td>\n",
       "      <td>0.547024</td>\n",
       "      <td>0.509307</td>\n",
       "      <td>0.519797</td>\n",
       "      <td>1250</td>\n",
       "      <td>0.720603</td>\n",
       "      <td>0.717600</td>\n",
       "      <td>0.715310</td>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.054600</td>\n",
       "      <td>2.063924</td>\n",
       "      <td>0.853015</td>\n",
       "      <td>0.856242</td>\n",
       "      <td>0.854626</td>\n",
       "      <td>793</td>\n",
       "      <td>0.503759</td>\n",
       "      <td>0.620370</td>\n",
       "      <td>0.556017</td>\n",
       "      <td>108</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.341463</td>\n",
       "      <td>0.394366</td>\n",
       "      <td>41</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.458824</td>\n",
       "      <td>0.561151</td>\n",
       "      <td>85</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.744186</td>\n",
       "      <td>20</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.472973</td>\n",
       "      <td>0.453074</td>\n",
       "      <td>148</td>\n",
       "      <td>0.377358</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>55</td>\n",
       "      <td>0.724000</td>\n",
       "      <td>0.579065</td>\n",
       "      <td>0.559073</td>\n",
       "      <td>0.561970</td>\n",
       "      <td>1250</td>\n",
       "      <td>0.728308</td>\n",
       "      <td>0.724000</td>\n",
       "      <td>0.723155</td>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.047100</td>\n",
       "      <td>2.157789</td>\n",
       "      <td>0.833726</td>\n",
       "      <td>0.891551</td>\n",
       "      <td>0.861670</td>\n",
       "      <td>793</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>108</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.414634</td>\n",
       "      <td>0.441558</td>\n",
       "      <td>41</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.546875</td>\n",
       "      <td>85</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.682927</td>\n",
       "      <td>20</td>\n",
       "      <td>0.483051</td>\n",
       "      <td>0.385135</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>148</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.309091</td>\n",
       "      <td>0.343434</td>\n",
       "      <td>55</td>\n",
       "      <td>0.735200</td>\n",
       "      <td>0.595753</td>\n",
       "      <td>0.539835</td>\n",
       "      <td>0.555097</td>\n",
       "      <td>1250</td>\n",
       "      <td>0.729048</td>\n",
       "      <td>0.735200</td>\n",
       "      <td>0.725262</td>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.023700</td>\n",
       "      <td>2.116953</td>\n",
       "      <td>0.852357</td>\n",
       "      <td>0.866330</td>\n",
       "      <td>0.859287</td>\n",
       "      <td>793</td>\n",
       "      <td>0.514706</td>\n",
       "      <td>0.648148</td>\n",
       "      <td>0.573770</td>\n",
       "      <td>108</td>\n",
       "      <td>0.511628</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>41</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.458824</td>\n",
       "      <td>0.577778</td>\n",
       "      <td>85</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>20</td>\n",
       "      <td>0.457746</td>\n",
       "      <td>0.439189</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>148</td>\n",
       "      <td>0.372549</td>\n",
       "      <td>0.345455</td>\n",
       "      <td>0.358491</td>\n",
       "      <td>55</td>\n",
       "      <td>0.733600</td>\n",
       "      <td>0.595829</td>\n",
       "      <td>0.577790</td>\n",
       "      <td>0.579385</td>\n",
       "      <td>1250</td>\n",
       "      <td>0.736526</td>\n",
       "      <td>0.733600</td>\n",
       "      <td>0.731453</td>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 00:12]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7352\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "num_labels = len(labels)\n",
    "models = []\n",
    "\n",
    "for i in range(num_folds):\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)\n",
    "    # import Fold data\n",
    "    train_origin, train_target, train_labels, test_origin, test_target, test_labels = import_fold(\"data/export-subset\", i)\n",
    "    # tokenize\n",
    "    train_encodings = tokenizer(train_origin, train_target, truncation=True, padding=True, return_token_type_ids=True)\n",
    "    test_encodings = tokenizer(test_origin, test_target, truncation=True, padding=True, return_token_type_ids=True)\n",
    "    # dataset creation\n",
    "    train_dataset = SemanticDataset(train_encodings, train_labels)\n",
    "    test_dataset = SemanticDataset(test_encodings, test_labels)\n",
    "    # create Trainer\n",
    "    trainer = Trainer(\n",
    "        model,\n",
    "        args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "    # train & evaluate\n",
    "    trainer.train()\n",
    "    ev = trainer.evaluate(test_dataset)\n",
    "    acc = ev[\"eval_accuracy\"]\n",
    "    print(f\"Accuracy: {acc}\")\n",
    "    result.append(ev)\n",
    "    models.append(trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e39bf6",
   "metadata": {},
   "source": [
    "## Interpret evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be62939",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a264f9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(data):\n",
    "    \"\"\"Return the sample arithmetic mean of data.\"\"\"\n",
    "    n = len(data)\n",
    "    if n < 1:\n",
    "        raise ValueError('mean requires at least one data point')\n",
    "    return sum(data)/n # in Python 2 use sum(data)/float(n)\n",
    "\n",
    "def _ss(data):\n",
    "    \"\"\"Return sum of square deviations of sequence data.\"\"\"\n",
    "    c = mean(data)\n",
    "    ss = sum((x-c)**2 for x in data)\n",
    "    return ss\n",
    "\n",
    "def stddev(data, ddof=0):\n",
    "    \"\"\"Calculates the population standard deviation\n",
    "    by default; specify ddof=1 to compute the sample\n",
    "    standard deviation.\"\"\"\n",
    "    n = len(data)\n",
    "    if n < 2:\n",
    "        raise ValueError('variance requires at least two data points')\n",
    "    ss = _ss(data)\n",
    "    pvar = ss/(n-ddof)\n",
    "    return pvar**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25d41df",
   "metadata": {},
   "source": [
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13df0f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'eval_loss': 1.9875022172927856,\n",
       "  'eval_none__precision': 0.8735332464146024,\n",
       "  'eval_none__recall': 0.8448928121059268,\n",
       "  'eval_none__f1-score': 0.8589743589743589,\n",
       "  'eval_none__support': 793,\n",
       "  'eval_causal__precision': 0.5658914728682171,\n",
       "  'eval_causal__recall': 0.6697247706422018,\n",
       "  'eval_causal__f1-score': 0.6134453781512605,\n",
       "  'eval_causal__support': 109,\n",
       "  'eval_contrast__precision': 0.6590909090909091,\n",
       "  'eval_contrast__recall': 0.6904761904761905,\n",
       "  'eval_contrast__f1-score': 0.6744186046511628,\n",
       "  'eval_contrast__support': 42,\n",
       "  'eval_equivalence__precision': 0.691358024691358,\n",
       "  'eval_equivalence__recall': 0.6588235294117647,\n",
       "  'eval_equivalence__f1-score': 0.674698795180723,\n",
       "  'eval_equivalence__support': 85,\n",
       "  'eval_identity__precision': 0.6842105263157895,\n",
       "  'eval_identity__recall': 0.65,\n",
       "  'eval_identity__f1-score': 0.6666666666666667,\n",
       "  'eval_identity__support': 20,\n",
       "  'eval_temporal__precision': 0.4228187919463087,\n",
       "  'eval_temporal__recall': 0.42857142857142855,\n",
       "  'eval_temporal__f1-score': 0.42567567567567566,\n",
       "  'eval_temporal__support': 147,\n",
       "  'eval_others__precision': 0.3870967741935484,\n",
       "  'eval_others__recall': 0.43636363636363634,\n",
       "  'eval_others__f1-score': 0.41025641025641024,\n",
       "  'eval_others__support': 55,\n",
       "  'eval_accuracy': 0.7418065547561951,\n",
       "  'eval_macro avg__precision': 0.611999963645819,\n",
       "  'eval_macro avg__recall': 0.6255503382244497,\n",
       "  'eval_macro avg__f1-score': 0.6177336985080368,\n",
       "  'eval_macro avg__support': 1251,\n",
       "  'eval_weighted avg__precision': 0.7497763235436189,\n",
       "  'eval_weighted avg__recall': 0.7418065547561951,\n",
       "  'eval_weighted avg__f1-score': 0.7451470440388686,\n",
       "  'eval_weighted avg__support': 1251,\n",
       "  'eval_runtime': 9.7904,\n",
       "  'eval_samples_per_second': 127.779,\n",
       "  'epoch': 10.0},\n",
       " {'eval_loss': 1.8617048263549805,\n",
       "  'eval_none__precision': 0.8604091456077015,\n",
       "  'eval_none__recall': 0.9016393442622951,\n",
       "  'eval_none__f1-score': 0.8805418719211822,\n",
       "  'eval_none__support': 793,\n",
       "  'eval_causal__precision': 0.603448275862069,\n",
       "  'eval_causal__recall': 0.6422018348623854,\n",
       "  'eval_causal__f1-score': 0.6222222222222221,\n",
       "  'eval_causal__support': 109,\n",
       "  'eval_contrast__precision': 0.5238095238095238,\n",
       "  'eval_contrast__recall': 0.5365853658536586,\n",
       "  'eval_contrast__f1-score': 0.5301204819277109,\n",
       "  'eval_contrast__support': 41,\n",
       "  'eval_equivalence__precision': 0.7866666666666666,\n",
       "  'eval_equivalence__recall': 0.6941176470588235,\n",
       "  'eval_equivalence__f1-score': 0.7374999999999999,\n",
       "  'eval_equivalence__support': 85,\n",
       "  'eval_identity__precision': 0.8,\n",
       "  'eval_identity__recall': 0.6,\n",
       "  'eval_identity__f1-score': 0.6857142857142857,\n",
       "  'eval_identity__support': 20,\n",
       "  'eval_temporal__precision': 0.5158730158730159,\n",
       "  'eval_temporal__recall': 0.4421768707482993,\n",
       "  'eval_temporal__f1-score': 0.4761904761904763,\n",
       "  'eval_temporal__support': 147,\n",
       "  'eval_others__precision': 0.45652173913043476,\n",
       "  'eval_others__recall': 0.375,\n",
       "  'eval_others__f1-score': 0.41176470588235287,\n",
       "  'eval_others__support': 56,\n",
       "  'eval_accuracy': 0.7705835331734612,\n",
       "  'eval_macro avg__precision': 0.6495326238499158,\n",
       "  'eval_macro avg__recall': 0.5988172946836373,\n",
       "  'eval_macro avg__f1-score': 0.6205791491226043,\n",
       "  'eval_macro avg__support': 1251,\n",
       "  'eval_weighted avg__precision': 0.7624474199867048,\n",
       "  'eval_weighted avg__recall': 0.7705835331734612,\n",
       "  'eval_weighted avg__f1-score': 0.7652178062817372,\n",
       "  'eval_weighted avg__support': 1251,\n",
       "  'eval_runtime': 9.9274,\n",
       "  'eval_samples_per_second': 126.014,\n",
       "  'epoch': 10.0},\n",
       " {'eval_loss': 2.1910295486450195,\n",
       "  'eval_none__precision': 0.8501259445843828,\n",
       "  'eval_none__recall': 0.8511979823455234,\n",
       "  'eval_none__f1-score': 0.8506616257088848,\n",
       "  'eval_none__support': 793,\n",
       "  'eval_causal__precision': 0.5511811023622047,\n",
       "  'eval_causal__recall': 0.6481481481481481,\n",
       "  'eval_causal__f1-score': 0.5957446808510638,\n",
       "  'eval_causal__support': 108,\n",
       "  'eval_contrast__precision': 0.4897959183673469,\n",
       "  'eval_contrast__recall': 0.5853658536585366,\n",
       "  'eval_contrast__f1-score': 0.5333333333333333,\n",
       "  'eval_contrast__support': 41,\n",
       "  'eval_equivalence__precision': 0.7714285714285715,\n",
       "  'eval_equivalence__recall': 0.6352941176470588,\n",
       "  'eval_equivalence__f1-score': 0.6967741935483872,\n",
       "  'eval_equivalence__support': 85,\n",
       "  'eval_identity__precision': 0.8333333333333334,\n",
       "  'eval_identity__recall': 0.5,\n",
       "  'eval_identity__f1-score': 0.625,\n",
       "  'eval_identity__support': 20,\n",
       "  'eval_temporal__precision': 0.38620689655172413,\n",
       "  'eval_temporal__recall': 0.3783783783783784,\n",
       "  'eval_temporal__f1-score': 0.3822525597269625,\n",
       "  'eval_temporal__support': 148,\n",
       "  'eval_others__precision': 0.2830188679245283,\n",
       "  'eval_others__recall': 0.2727272727272727,\n",
       "  'eval_others__f1-score': 0.2777777777777778,\n",
       "  'eval_others__support': 55,\n",
       "  'eval_accuracy': 0.7232,\n",
       "  'eval_macro avg__precision': 0.5950129477931559,\n",
       "  'eval_macro avg__recall': 0.5530159647007026,\n",
       "  'eval_macro avg__f1-score': 0.5659348815637727,\n",
       "  'eval_macro avg__support': 1250,\n",
       "  'eval_weighted avg__precision': 0.7269774555417554,\n",
       "  'eval_weighted avg__recall': 0.7232,\n",
       "  'eval_weighted avg__f1-score': 0.7234869795637667,\n",
       "  'eval_weighted avg__support': 1250,\n",
       "  'eval_runtime': 9.5813,\n",
       "  'eval_samples_per_second': 130.463,\n",
       "  'epoch': 10.0},\n",
       " {'eval_loss': 2.1577887535095215,\n",
       "  'eval_none__precision': 0.8337264150943396,\n",
       "  'eval_none__recall': 0.8915510718789408,\n",
       "  'eval_none__f1-score': 0.8616697135892748,\n",
       "  'eval_none__support': 793,\n",
       "  'eval_causal__precision': 0.5142857142857142,\n",
       "  'eval_causal__recall': 0.6666666666666666,\n",
       "  'eval_causal__f1-score': 0.5806451612903226,\n",
       "  'eval_causal__support': 108,\n",
       "  'eval_contrast__precision': 0.4722222222222222,\n",
       "  'eval_contrast__recall': 0.4146341463414634,\n",
       "  'eval_contrast__f1-score': 0.4415584415584415,\n",
       "  'eval_contrast__support': 41,\n",
       "  'eval_equivalence__precision': 0.813953488372093,\n",
       "  'eval_equivalence__recall': 0.4117647058823529,\n",
       "  'eval_equivalence__f1-score': 0.546875,\n",
       "  'eval_equivalence__support': 85,\n",
       "  'eval_identity__precision': 0.6666666666666666,\n",
       "  'eval_identity__recall': 0.7,\n",
       "  'eval_identity__f1-score': 0.6829268292682926,\n",
       "  'eval_identity__support': 20,\n",
       "  'eval_temporal__precision': 0.4830508474576271,\n",
       "  'eval_temporal__recall': 0.38513513513513514,\n",
       "  'eval_temporal__f1-score': 0.42857142857142855,\n",
       "  'eval_temporal__support': 148,\n",
       "  'eval_others__precision': 0.38636363636363635,\n",
       "  'eval_others__recall': 0.3090909090909091,\n",
       "  'eval_others__f1-score': 0.3434343434343434,\n",
       "  'eval_others__support': 55,\n",
       "  'eval_accuracy': 0.7352,\n",
       "  'eval_macro avg__precision': 0.5957527129231857,\n",
       "  'eval_macro avg__recall': 0.5398346621422097,\n",
       "  'eval_macro avg__f1-score': 0.5550972739588719,\n",
       "  'eval_macro avg__support': 1250,\n",
       "  'eval_weighted avg__precision': 0.7290479365539757,\n",
       "  'eval_weighted avg__recall': 0.7352,\n",
       "  'eval_weighted avg__f1-score': 0.7252624226418977,\n",
       "  'eval_weighted avg__support': 1250,\n",
       "  'eval_runtime': 12.2108,\n",
       "  'eval_samples_per_second': 102.368,\n",
       "  'epoch': 10.0}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70dad3cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_none__precision</th>\n",
       "      <th>eval_none__recall</th>\n",
       "      <th>eval_none__f1-score</th>\n",
       "      <th>eval_none__support</th>\n",
       "      <th>eval_causal__precision</th>\n",
       "      <th>eval_causal__recall</th>\n",
       "      <th>eval_causal__f1-score</th>\n",
       "      <th>eval_causal__support</th>\n",
       "      <th>eval_contrast__precision</th>\n",
       "      <th>eval_contrast__recall</th>\n",
       "      <th>eval_contrast__f1-score</th>\n",
       "      <th>eval_contrast__support</th>\n",
       "      <th>eval_equivalence__precision</th>\n",
       "      <th>eval_equivalence__recall</th>\n",
       "      <th>eval_equivalence__f1-score</th>\n",
       "      <th>eval_equivalence__support</th>\n",
       "      <th>eval_identity__precision</th>\n",
       "      <th>eval_identity__recall</th>\n",
       "      <th>eval_identity__f1-score</th>\n",
       "      <th>eval_identity__support</th>\n",
       "      <th>eval_temporal__precision</th>\n",
       "      <th>eval_temporal__recall</th>\n",
       "      <th>eval_temporal__f1-score</th>\n",
       "      <th>eval_temporal__support</th>\n",
       "      <th>eval_others__precision</th>\n",
       "      <th>eval_others__recall</th>\n",
       "      <th>eval_others__f1-score</th>\n",
       "      <th>eval_others__support</th>\n",
       "      <th>eval_accuracy</th>\n",
       "      <th>eval_macro avg__precision</th>\n",
       "      <th>eval_macro avg__recall</th>\n",
       "      <th>eval_macro avg__f1-score</th>\n",
       "      <th>eval_macro avg__support</th>\n",
       "      <th>eval_weighted avg__precision</th>\n",
       "      <th>eval_weighted avg__recall</th>\n",
       "      <th>eval_weighted avg__f1-score</th>\n",
       "      <th>eval_weighted avg__support</th>\n",
       "      <th>eval_runtime</th>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.987502</td>\n",
       "      <td>0.873533</td>\n",
       "      <td>0.844893</td>\n",
       "      <td>0.858974</td>\n",
       "      <td>793.0</td>\n",
       "      <td>0.565891</td>\n",
       "      <td>0.669725</td>\n",
       "      <td>0.613445</td>\n",
       "      <td>109.00000</td>\n",
       "      <td>0.659091</td>\n",
       "      <td>0.690476</td>\n",
       "      <td>0.674419</td>\n",
       "      <td>42.00</td>\n",
       "      <td>0.691358</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>0.674699</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.422819</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.425676</td>\n",
       "      <td>147.00000</td>\n",
       "      <td>0.387097</td>\n",
       "      <td>0.436364</td>\n",
       "      <td>0.410256</td>\n",
       "      <td>55.00</td>\n",
       "      <td>0.741807</td>\n",
       "      <td>0.612000</td>\n",
       "      <td>0.625550</td>\n",
       "      <td>0.617734</td>\n",
       "      <td>1251.00000</td>\n",
       "      <td>0.749776</td>\n",
       "      <td>0.741807</td>\n",
       "      <td>0.745147</td>\n",
       "      <td>1251.00000</td>\n",
       "      <td>9.790400</td>\n",
       "      <td>127.779000</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.861705</td>\n",
       "      <td>0.860409</td>\n",
       "      <td>0.901639</td>\n",
       "      <td>0.880542</td>\n",
       "      <td>793.0</td>\n",
       "      <td>0.603448</td>\n",
       "      <td>0.642202</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>109.00000</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>0.530120</td>\n",
       "      <td>41.00</td>\n",
       "      <td>0.786667</td>\n",
       "      <td>0.694118</td>\n",
       "      <td>0.737500</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.515873</td>\n",
       "      <td>0.442177</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>147.00000</td>\n",
       "      <td>0.456522</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>56.00</td>\n",
       "      <td>0.770584</td>\n",
       "      <td>0.649533</td>\n",
       "      <td>0.598817</td>\n",
       "      <td>0.620579</td>\n",
       "      <td>1251.00000</td>\n",
       "      <td>0.762447</td>\n",
       "      <td>0.770584</td>\n",
       "      <td>0.765218</td>\n",
       "      <td>1251.00000</td>\n",
       "      <td>9.927400</td>\n",
       "      <td>126.014000</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.191030</td>\n",
       "      <td>0.850126</td>\n",
       "      <td>0.851198</td>\n",
       "      <td>0.850662</td>\n",
       "      <td>793.0</td>\n",
       "      <td>0.551181</td>\n",
       "      <td>0.648148</td>\n",
       "      <td>0.595745</td>\n",
       "      <td>108.00000</td>\n",
       "      <td>0.489796</td>\n",
       "      <td>0.585366</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>41.00</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.635294</td>\n",
       "      <td>0.696774</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.386207</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.382253</td>\n",
       "      <td>148.00000</td>\n",
       "      <td>0.283019</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>55.00</td>\n",
       "      <td>0.723200</td>\n",
       "      <td>0.595013</td>\n",
       "      <td>0.553016</td>\n",
       "      <td>0.565935</td>\n",
       "      <td>1250.00000</td>\n",
       "      <td>0.726977</td>\n",
       "      <td>0.723200</td>\n",
       "      <td>0.723487</td>\n",
       "      <td>1250.00000</td>\n",
       "      <td>9.581300</td>\n",
       "      <td>130.463000</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.157789</td>\n",
       "      <td>0.833726</td>\n",
       "      <td>0.891551</td>\n",
       "      <td>0.861670</td>\n",
       "      <td>793.0</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>108.00000</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.414634</td>\n",
       "      <td>0.441558</td>\n",
       "      <td>41.00</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.546875</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.682927</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.483051</td>\n",
       "      <td>0.385135</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>148.00000</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.309091</td>\n",
       "      <td>0.343434</td>\n",
       "      <td>55.00</td>\n",
       "      <td>0.735200</td>\n",
       "      <td>0.595753</td>\n",
       "      <td>0.539835</td>\n",
       "      <td>0.555097</td>\n",
       "      <td>1250.00000</td>\n",
       "      <td>0.729048</td>\n",
       "      <td>0.735200</td>\n",
       "      <td>0.725262</td>\n",
       "      <td>1250.00000</td>\n",
       "      <td>12.210800</td>\n",
       "      <td>102.368000</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg</th>\n",
       "      <td>2.049506</td>\n",
       "      <td>0.854449</td>\n",
       "      <td>0.872320</td>\n",
       "      <td>0.862962</td>\n",
       "      <td>793.0</td>\n",
       "      <td>0.558702</td>\n",
       "      <td>0.656685</td>\n",
       "      <td>0.603014</td>\n",
       "      <td>108.50000</td>\n",
       "      <td>0.536230</td>\n",
       "      <td>0.556765</td>\n",
       "      <td>0.544858</td>\n",
       "      <td>41.25</td>\n",
       "      <td>0.765852</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.663962</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.746053</td>\n",
       "      <td>0.612500</td>\n",
       "      <td>0.665077</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.451987</td>\n",
       "      <td>0.408565</td>\n",
       "      <td>0.428173</td>\n",
       "      <td>147.50000</td>\n",
       "      <td>0.378250</td>\n",
       "      <td>0.348295</td>\n",
       "      <td>0.360808</td>\n",
       "      <td>55.25</td>\n",
       "      <td>0.742698</td>\n",
       "      <td>0.613075</td>\n",
       "      <td>0.579305</td>\n",
       "      <td>0.589836</td>\n",
       "      <td>1250.50000</td>\n",
       "      <td>0.742062</td>\n",
       "      <td>0.742698</td>\n",
       "      <td>0.739779</td>\n",
       "      <td>1250.50000</td>\n",
       "      <td>10.377475</td>\n",
       "      <td>121.656000</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.153696</td>\n",
       "      <td>0.016811</td>\n",
       "      <td>0.028448</td>\n",
       "      <td>0.012622</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036893</td>\n",
       "      <td>0.013568</td>\n",
       "      <td>0.018538</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.084660</td>\n",
       "      <td>0.114463</td>\n",
       "      <td>0.096275</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.052686</td>\n",
       "      <td>0.127797</td>\n",
       "      <td>0.082278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.082976</td>\n",
       "      <td>0.085391</td>\n",
       "      <td>0.028007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058379</td>\n",
       "      <td>0.031571</td>\n",
       "      <td>0.038387</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.071506</td>\n",
       "      <td>0.072380</td>\n",
       "      <td>0.063869</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.020123</td>\n",
       "      <td>0.025538</td>\n",
       "      <td>0.039868</td>\n",
       "      <td>0.034164</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.017049</td>\n",
       "      <td>0.020123</td>\n",
       "      <td>0.019597</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>1.230474</td>\n",
       "      <td>12.988116</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def transform_to_regular_dict(result):\n",
    "    output_dict = {}\n",
    "    count = 0\n",
    "    for eval_item in result:\n",
    "        for key in eval_item:\n",
    "            if count == 0:\n",
    "              output_dict[key] = [float(eval_item[key])]\n",
    "            else:\n",
    "              output_dict[key].append(eval_item[key]) \n",
    "        count += 1\n",
    "    return output_dict\n",
    "            \n",
    "eval_dict = transform_to_regular_dict(result)\n",
    "eval_df = pd.DataFrame(eval_dict)\n",
    "\n",
    "def add_mean_std_row(df):\n",
    "    row_mean = []\n",
    "    row_std = []\n",
    "    for column in df:\n",
    "        row_mean.append(mean(df[column]))\n",
    "        row_std.append(stddev(df[column], ddof=1))\n",
    "    df = df.append(pd.DataFrame([row_mean], columns=df.columns), ignore_index=True)\n",
    "    df = df.append(pd.DataFrame([row_std], columns=df.columns), ignore_index=True)\n",
    "    # add better readable Index\n",
    "    df[\"fold\"] = [\"1\", \"2\", \"3\", \"4\", \"avg\", \"std\"]\n",
    "    df = df.set_index(\"fold\")\n",
    "    return df\n",
    "\n",
    "eval_df = add_mean_std_row(eval_df)\n",
    "display(HTML(eval_df.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ad0e60",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df57efb",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed76e5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for model in models:\n",
    "    model.save_model(f\"/data/experiments/raring/semantic_storytelling/data/model-subset/{model_checkpoint.replace(r'/', '-')}/epoch_{num_epoch}/fold_{count}\")\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd633be",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff5f2271",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df.to_csv(f\"data/eval-subset/{model_checkpoint.replace(r'/', '-')}_epoch_{num_epoch}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ef9e14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
